2023-08-10 02:28:26,160 - allrank.utils.ltr_logging - INFO - created paths container PathsContainer(local_base_output_path='results-new/', base_output_path='results-new/', output_dir='results-new/results\\analiseyahoo', tensorboard_output_path='results-new/tb_evals\\single\\analiseyahoo', config_path='localtemp_config.json')
2023-08-10 02:28:26,161 - allrank.utils.ltr_logging - INFO - Config:
 {'click_model': None,
 'data': DataConfig(path='D:\\Colecoes\\BD\\yahoo-c14\\l2r', num_workers=0, batch_size=20, slate_length=100, validation_ds_role='vali'),
 'detect_anomaly': True,
 'expected_metrics': {'val': {'georisk_10': 0.0,
                              'lndcg_10': 0.0,
                              'lndcg_5': 0.0,
                              'ndcg_10': 0.0,
                              'ndcg_5': 0.0}},
 'loss': NameArgsConfig(name='geoRiskSpearmanLoss', args={}),
 'lr_scheduler': NameArgsConfig(name=None, args={'step_size': 800, 'gamma': 0.5}),
 'metrics': defaultdict(<class 'list'>,
                        {'georisk': [10],
                         'lndcg': [5,
                                   10],
                         'lndcg1': [5,
                                    10],
                         'ndcg': [5,
                                  10],
                         'ndcg1': [5,
                                   10]}),
 'model': ModelConfig(fc_model={}, transformer=TransformerConfig(N=2, d_ff=32, h=2, positional_encoding=None, dropout=0.3), post_model={'output_activation': 'Sigmoid', 'd_output': 1}),
 'optimizer': NameArgsConfig(name='Adam', args={'lr': 0.0001}),
 'training': TrainingConfig(epochs=25, gradient_clipping_norm=None, early_stopping_patience=100),
 'val_metric': 'ndcg_10'}
2023-08-10 02:28:26,162 - allrank.utils.ltr_logging - INFO - will execute copy "localtemp_config.json" "results-new/results\analiseyahoo\used_config.json"
2023-08-10 02:28:26,189 - allrank.utils.ltr_logging - INFO - exit_code = 0
2023-08-10 02:28:26,189 - allrank.utils.ltr_logging - INFO - will load train data from D:\Colecoes\BD\yahoo-c14\l2r\Norm.train.txt
2023-08-10 02:28:30,880 - allrank.utils.ltr_logging - INFO - loaded dataset from <_io.BufferedReader name='D:\\Colecoes\\BD\\yahoo-c14\\l2r\\Norm.train.txt'> and got x shape (34815, 700), y shape (34815,) and query_ids shape (34815,)
2023-08-10 02:28:30,937 - allrank.utils.ltr_logging - INFO - loaded dataset with 1266 queries
2023-08-10 02:28:30,937 - allrank.utils.ltr_logging - INFO - longest query had 117 documents
2023-08-10 02:28:30,944 - allrank.utils.ltr_logging - INFO - train DS shape: [1266, 117, 700]
2023-08-10 02:28:30,944 - allrank.utils.ltr_logging - INFO - will load vali data from D:\Colecoes\BD\yahoo-c14\l2r\Norm.vali.txt
2023-08-10 02:28:35,652 - allrank.utils.ltr_logging - INFO - loaded dataset from <_io.BufferedReader name='D:\\Colecoes\\BD\\yahoo-c14\\l2r\\Norm.vali.txt'> and got x shape (34881, 700), y shape (34881,) and query_ids shape (34881,)
2023-08-10 02:28:35,708 - allrank.utils.ltr_logging - INFO - loaded dataset with 1266 queries
2023-08-10 02:28:35,708 - allrank.utils.ltr_logging - INFO - longest query had 118 documents
2023-08-10 02:28:35,715 - allrank.utils.ltr_logging - INFO - vali DS shape: [1266, 118, 700]
2023-08-10 02:28:35,716 - allrank.utils.ltr_logging - INFO - Will pad to the longest slate: 118
2023-08-10 02:28:35,716 - allrank.utils.ltr_logging - INFO - will load test data from D:\Colecoes\BD\yahoo-c14\l2r\Norm.test.txt
2023-08-10 02:28:40,353 - allrank.utils.ltr_logging - INFO - loaded dataset from <_io.BufferedReader name='D:\\Colecoes\\BD\\yahoo-c14\\l2r\\Norm.test.txt'> and got x shape (34881, 700), y shape (34881,) and query_ids shape (34881,)
2023-08-10 02:28:40,416 - allrank.utils.ltr_logging - INFO - loaded dataset with 1266 queries
2023-08-10 02:28:40,416 - allrank.utils.ltr_logging - INFO - longest query had 118 documents
2023-08-10 02:28:40,424 - allrank.utils.ltr_logging - INFO - test DS shape: [1266, 118, 700]
2023-08-10 02:28:40,424 - allrank.utils.ltr_logging - INFO - Will pad to the longest slate: 118
2023-08-10 02:28:40,426 - allrank.utils.ltr_logging - INFO - total batch size is 20
2023-08-10 02:28:40,427 - allrank.utils.ltr_logging - INFO - Model training will execute on cpu
2023-08-10 02:28:40,466 - allrank.utils.ltr_logging - INFO - Model has 4024365 trainable parameters
2023-08-10 02:28:40,467 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 02:43:21,056 - allrank.utils.ltr_logging - INFO - Epoch : 0 Train loss: 0.2747219307774804 Val loss: 0.23275271091039335 Train ndcg_5 0.41963163018226624 Train ndcg_10 0.5000848770141602 Train lndcg_5 0.5343219041824341 Train lndcg_10 0.6027869582176208 Train lndcg1_5 0.550774872303009 Train lndcg1_10 0.6200681924819946 Train ndcg1_5 0.43551579117774963 Train ndcg1_10 0.5151742100715637 Train georisk_10 0.4488844871520996 Val ndcg_5 0.40791386365890503 Val ndcg_10 0.49079662561416626 Val lndcg_5 0.5284556746482849 Val lndcg_10 0.6011630892753601 Val lndcg1_5 0.5466229915618896 Val lndcg1_10 0.6193305253982544 Val ndcg1_5 0.42608126997947693 Val ndcg1_10 0.5089641213417053 Val georisk_10 0.44015973806381226
2023-08-10 02:43:21,057 - allrank.utils.ltr_logging - INFO - Current:0.49079662561416626 Best:0.0
2023-08-10 02:43:39,168 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.4079063522475752, 'ndcg_10': 0.4907767410632243, 'lndcg_5': 0.5284446777850241, 'lndcg_10': 0.6011378412779609, 'lndcg1_5': 0.5466121343411063, 'lndcg1_10': 0.619305297834043, 'ndcg1_5': 0.42607380880365736, 'ndcg1_10': 0.5089441976193064} 
2023-08-10 02:43:39,168 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 02:58:19,196 - allrank.utils.ltr_logging - INFO - Epoch : 1 Train loss: 0.22078264343418405 Val loss: 0.23075140704287547 Train ndcg_5 0.4081052541732788 Train ndcg_10 0.48666343092918396 Train lndcg_5 0.5277834534645081 Train lndcg_10 0.600131094455719 Train lndcg1_5 0.5479238629341125 Train lndcg1_10 0.6212714314460754 Train ndcg1_5 0.4341423511505127 Train ndcg1_10 0.5130478143692017 Train georisk_10 0.4445136785507202 Val ndcg_5 0.4011159837245941 Val ndcg_10 0.4816814363002777 Val lndcg_5 0.5234181880950928 Val lndcg_10 0.5943129062652588 Val lndcg1_5 0.5415857434272766 Val lndcg1_10 0.6124804019927979 Val ndcg1_5 0.41928327083587646 Val ndcg1_10 0.4998490512371063 Val georisk_10 0.4358260929584503
2023-08-10 02:58:19,198 - allrank.utils.ltr_logging - INFO - Current:0.4816814363002777 Best:0.49079662561416626
2023-08-10 02:58:37,815 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 14:55:21,578 - allrank.utils.ltr_logging - INFO - created paths container PathsContainer(local_base_output_path='results-new/', base_output_path='results-new/', output_dir='results-new/results\\analiseyahoo', tensorboard_output_path='results-new/tb_evals\\single\\analiseyahoo', config_path='localtemp_config.json')
2023-08-10 14:55:21,593 - allrank.utils.ltr_logging - INFO - Config:
 {'click_model': None,
 'data': DataConfig(path='D:\\Colecoes\\BD\\yahoo-c14\\l2r', num_workers=0, batch_size=20, slate_length=100, validation_ds_role='vali'),
 'detect_anomaly': True,
 'expected_metrics': {'val': {'georisk_10': 0.0,
                              'lndcg_10': 0.0,
                              'lndcg_5': 0.0,
                              'ndcg_10': 0.0,
                              'ndcg_5': 0.0}},
 'loss': NameArgsConfig(name='geoRiskSpearmanLoss', args={}),
 'lr_scheduler': NameArgsConfig(name=None, args={'step_size': 800, 'gamma': 0.5}),
 'metrics': defaultdict(<class 'list'>,
                        {'georisk': [10],
                         'lndcg': [5,
                                   10],
                         'lndcg1': [5,
                                    10],
                         'ndcg': [5,
                                  10],
                         'ndcg1': [5,
                                   10]}),
 'model': ModelConfig(fc_model={}, transformer=TransformerConfig(N=2, d_ff=32, h=2, positional_encoding=None, dropout=0.3), post_model={'output_activation': 'Sigmoid', 'd_output': 1}),
 'optimizer': NameArgsConfig(name='Adam', args={'lr': 0.0001}),
 'training': TrainingConfig(epochs=25, gradient_clipping_norm=None, early_stopping_patience=100),
 'val_metric': 'ndcg_10'}
2023-08-10 14:55:21,593 - allrank.utils.ltr_logging - INFO - will execute copy "localtemp_config.json" "results-new/results\analiseyahoo\used_config.json"
2023-08-10 14:55:21,625 - allrank.utils.ltr_logging - INFO - exit_code = 0
2023-08-10 14:55:21,625 - allrank.utils.ltr_logging - INFO - will load train data from D:\Colecoes\BD\yahoo-c14\l2r\Norm.train.txt
2023-08-10 14:55:26,442 - allrank.utils.ltr_logging - INFO - loaded dataset from <_io.BufferedReader name='D:\\Colecoes\\BD\\yahoo-c14\\l2r\\Norm.train.txt'> and got x shape (34815, 700), y shape (34815,) and query_ids shape (34815,)
2023-08-10 14:55:26,488 - allrank.utils.ltr_logging - INFO - loaded dataset with 1266 queries
2023-08-10 14:55:26,488 - allrank.utils.ltr_logging - INFO - longest query had 117 documents
2023-08-10 14:55:26,504 - allrank.utils.ltr_logging - INFO - train DS shape: [1266, 117, 700]
2023-08-10 14:55:26,504 - allrank.utils.ltr_logging - INFO - will load vali data from D:\Colecoes\BD\yahoo-c14\l2r\Norm.vali.txt
2023-08-10 14:55:31,280 - allrank.utils.ltr_logging - INFO - loaded dataset from <_io.BufferedReader name='D:\\Colecoes\\BD\\yahoo-c14\\l2r\\Norm.vali.txt'> and got x shape (34881, 700), y shape (34881,) and query_ids shape (34881,)
2023-08-10 14:55:31,374 - allrank.utils.ltr_logging - INFO - loaded dataset with 1266 queries
2023-08-10 14:55:31,374 - allrank.utils.ltr_logging - INFO - longest query had 118 documents
2023-08-10 14:55:31,390 - allrank.utils.ltr_logging - INFO - vali DS shape: [1266, 118, 700]
2023-08-10 14:55:31,390 - allrank.utils.ltr_logging - INFO - Will pad to the longest slate: 118
2023-08-10 14:55:31,390 - allrank.utils.ltr_logging - INFO - will load test data from D:\Colecoes\BD\yahoo-c14\l2r\Norm.test.txt
2023-08-10 14:55:36,140 - allrank.utils.ltr_logging - INFO - loaded dataset from <_io.BufferedReader name='D:\\Colecoes\\BD\\yahoo-c14\\l2r\\Norm.test.txt'> and got x shape (34881, 700), y shape (34881,) and query_ids shape (34881,)
2023-08-10 14:55:36,218 - allrank.utils.ltr_logging - INFO - loaded dataset with 1266 queries
2023-08-10 14:55:36,218 - allrank.utils.ltr_logging - INFO - longest query had 118 documents
2023-08-10 14:55:36,218 - allrank.utils.ltr_logging - INFO - test DS shape: [1266, 118, 700]
2023-08-10 14:55:36,218 - allrank.utils.ltr_logging - INFO - Will pad to the longest slate: 118
2023-08-10 14:55:36,218 - allrank.utils.ltr_logging - INFO - total batch size is 20
2023-08-10 14:55:36,218 - allrank.utils.ltr_logging - INFO - Model training will execute on cpu
2023-08-10 14:55:36,265 - allrank.utils.ltr_logging - INFO - Model has 4024365 trainable parameters
2023-08-10 14:55:36,265 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 15:10:34,320 - allrank.utils.ltr_logging - INFO - Epoch : 0 Train loss: 0.2747219307774804 Val loss: 0.23275271091039335 Train ndcg_5 0.41963163018226624 Train ndcg_10 0.5000848770141602 Train lndcg_5 0.5343219041824341 Train lndcg_10 0.6027869582176208 Train lndcg1_5 0.550774872303009 Train lndcg1_10 0.6200681924819946 Train ndcg1_5 0.43551579117774963 Train ndcg1_10 0.5151742100715637 Train georisk_10 0.4488844871520996 Val ndcg_5 0.40791386365890503 Val ndcg_10 0.49079662561416626 Val lndcg_5 0.5284556746482849 Val lndcg_10 0.6011630892753601 Val lndcg1_5 0.5466229915618896 Val lndcg1_10 0.6193305253982544 Val ndcg1_5 0.42608126997947693 Val ndcg1_10 0.5089641213417053 Val georisk_10 0.44015973806381226
2023-08-10 15:10:34,320 - allrank.utils.ltr_logging - INFO - Current:0.49079662561416626 Best:0.0
2023-08-10 15:10:53,930 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.4079063522475752, 'ndcg_10': 0.4907767410632243, 'lndcg_5': 0.5284446777850241, 'lndcg_10': 0.6011378412779609, 'lndcg1_5': 0.5466121343411063, 'lndcg1_10': 0.619305297834043, 'ndcg1_5': 0.42607380880365736, 'ndcg1_10': 0.5089441976193064} 
2023-08-10 15:10:53,930 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 15:25:52,950 - allrank.utils.ltr_logging - INFO - Epoch : 1 Train loss: 0.22078264343418405 Val loss: 0.23075140704287547 Train ndcg_5 0.4081052541732788 Train ndcg_10 0.48666343092918396 Train lndcg_5 0.5277834534645081 Train lndcg_10 0.600131094455719 Train lndcg1_5 0.5479238629341125 Train lndcg1_10 0.6212714314460754 Train ndcg1_5 0.4341423511505127 Train ndcg1_10 0.5130478143692017 Train georisk_10 0.4445136785507202 Val ndcg_5 0.4011159837245941 Val ndcg_10 0.4816814363002777 Val lndcg_5 0.5234181880950928 Val lndcg_10 0.5943129062652588 Val lndcg1_5 0.5415857434272766 Val lndcg1_10 0.6124804019927979 Val ndcg1_5 0.41928327083587646 Val ndcg1_10 0.4998490512371063 Val georisk_10 0.4358260929584503
2023-08-10 15:25:52,950 - allrank.utils.ltr_logging - INFO - Current:0.4816814363002777 Best:0.49079662561416626
2023-08-10 15:26:12,280 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 15:41:13,267 - allrank.utils.ltr_logging - INFO - Epoch : 2 Train loss: 0.2173021981878115 Val loss: 0.23072186870409225 Train ndcg_5 0.41464290022850037 Train ndcg_10 0.4940582811832428 Train lndcg_5 0.5293852686882019 Train lndcg_10 0.5993241667747498 Train lndcg1_5 0.5475096702575684 Train lndcg1_10 0.6169368624687195 Train ndcg1_5 0.4339118003845215 Train ndcg1_10 0.514564573764801 Train georisk_10 0.4411529004573822 Val ndcg_5 0.3956323266029358 Val ndcg_10 0.47781580686569214 Val lndcg_5 0.5186901092529297 Val lndcg_10 0.5909008979797363 Val lndcg1_5 0.5368574857711792 Val lndcg1_10 0.6090683341026306 Val ndcg1_5 0.4137996435165405 Val ndcg1_10 0.49598339200019836 Val georisk_10 0.4341493546962738
2023-08-10 15:41:13,267 - allrank.utils.ltr_logging - INFO - Current:0.47781580686569214 Best:0.49079662561416626
2023-08-10 15:41:32,738 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 15:56:33,120 - allrank.utils.ltr_logging - INFO - Epoch : 3 Train loss: 0.21712595066658882 Val loss: 0.2304618930882564 Train ndcg_5 0.4155142903327942 Train ndcg_10 0.49327003955841064 Train lndcg_5 0.5306881666183472 Train lndcg_10 0.599124014377594 Train lndcg1_5 0.5535964369773865 Train lndcg1_10 0.6226922273635864 Train ndcg1_5 0.43537938594818115 Train ndcg1_10 0.5183035731315613 Train georisk_10 0.44383299350738525 Val ndcg_5 0.395122766494751 Val ndcg_10 0.476528525352478 Val lndcg_5 0.5187164545059204 Val lndcg_10 0.5902114510536194 Val lndcg1_5 0.5368838906288147 Val lndcg1_10 0.6083788871765137 Val ndcg1_5 0.4132902920246124 Val ndcg1_10 0.4946960508823395 Val georisk_10 0.43312498927116394
2023-08-10 15:56:33,120 - allrank.utils.ltr_logging - INFO - Current:0.476528525352478 Best:0.49079662561416626
2023-08-10 15:56:51,886 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 16:11:51,985 - allrank.utils.ltr_logging - INFO - Epoch : 4 Train loss: 0.21683553153116367 Val loss: 0.23048567651854873 Train ndcg_5 0.4140203595161438 Train ndcg_10 0.49707353115081787 Train lndcg_5 0.5309433341026306 Train lndcg_10 0.6023319363594055 Train lndcg1_5 0.5577659010887146 Train lndcg1_10 0.6274681091308594 Train ndcg1_5 0.4394971430301666 Train ndcg1_10 0.5179311037063599 Train georisk_10 0.44470906257629395 Val ndcg_5 0.3978995978832245 Val ndcg_10 0.478760689496994 Val lndcg_5 0.5209347605705261 Val lndcg_10 0.5914244651794434 Val lndcg1_5 0.5391210913658142 Val lndcg1_10 0.6096049547195435 Val ndcg1_5 0.4160540997982025 Val ndcg1_10 0.49691522121429443 Val georisk_10 0.43398517370224
2023-08-10 16:11:52,001 - allrank.utils.ltr_logging - INFO - Current:0.478760689496994 Best:0.49079662561416626
2023-08-10 16:12:11,565 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 16:27:12,705 - allrank.utils.ltr_logging - INFO - Epoch : 5 Train loss: 0.21460890551031483 Val loss: 0.23022031400346832 Train ndcg_5 0.40614765882492065 Train ndcg_10 0.4878533184528351 Train lndcg_5 0.5231467485427856 Train lndcg_10 0.5969889760017395 Train lndcg1_5 0.5513193607330322 Train lndcg1_10 0.6234750151634216 Train ndcg1_5 0.435307115316391 Train ndcg1_10 0.5151981115341187 Train georisk_10 0.4454594850540161 Val ndcg_5 0.3982273042201996 Val ndcg_10 0.4799942970275879 Val lndcg_5 0.5221377611160278 Val lndcg_10 0.5932217240333557 Val lndcg1_5 0.5403052568435669 Val lndcg1_10 0.6113891005516052 Val ndcg1_5 0.41639477014541626 Val ndcg1_10 0.4981619119644165 Val georisk_10 0.4360404908657074
2023-08-10 16:27:12,705 - allrank.utils.ltr_logging - INFO - Current:0.4799942970275879 Best:0.49079662561416626
2023-08-10 16:27:31,785 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 16:42:33,567 - allrank.utils.ltr_logging - INFO - Epoch : 6 Train loss: 0.21651509997404017 Val loss: 0.2303058583212878 Train ndcg_5 0.41079407930374146 Train ndcg_10 0.49108341336250305 Train lndcg_5 0.5322884917259216 Train lndcg_10 0.6012271642684937 Train lndcg1_5 0.5453501343727112 Train lndcg1_10 0.617927610874176 Train ndcg1_5 0.4313477575778961 Train ndcg1_10 0.5139933228492737 Train georisk_10 0.447874516248703 Val ndcg_5 0.3954634964466095 Val ndcg_10 0.4782634377479553 Val lndcg_5 0.518379807472229 Val lndcg_10 0.5910356044769287 Val lndcg1_5 0.5365472435951233 Val lndcg1_10 0.6092029809951782 Val ndcg1_5 0.4136309027671814 Val ndcg1_10 0.49642810225486755 Val georisk_10 0.43520134687423706
2023-08-10 16:42:33,567 - allrank.utils.ltr_logging - INFO - Current:0.4782634377479553 Best:0.49079662561416626
2023-08-10 16:42:52,505 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 16:57:53,418 - allrank.utils.ltr_logging - INFO - Epoch : 7 Train loss: 0.2149684910572724 Val loss: 0.23035944155513016 Train ndcg_5 0.4191053807735443 Train ndcg_10 0.49816349148750305 Train lndcg_5 0.5266913771629333 Train lndcg_10 0.5998911261558533 Train lndcg1_5 0.5485747456550598 Train lndcg1_10 0.6208124160766602 Train ndcg1_5 0.4419995844364166 Train ndcg1_10 0.5187772512435913 Train georisk_10 0.44461631774902344 Val ndcg_5 0.3981626033782959 Val ndcg_10 0.48121294379234314 Val lndcg_5 0.520768940448761 Val lndcg_10 0.5936252474784851 Val lndcg1_5 0.5389363765716553 Val lndcg1_10 0.61179518699646 Val ndcg1_5 0.41632986068725586 Val ndcg1_10 0.49938222765922546 Val georisk_10 0.4371967315673828
2023-08-10 16:57:53,434 - allrank.utils.ltr_logging - INFO - Current:0.48121294379234314 Best:0.49079662561416626
2023-08-10 16:58:12,405 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 17:13:13,787 - allrank.utils.ltr_logging - INFO - Epoch : 8 Train loss: 0.2154245127998822 Val loss: 0.23006763279814668 Train ndcg_5 0.41246458888053894 Train ndcg_10 0.4991944432258606 Train lndcg_5 0.5314170718193054 Train lndcg_10 0.6010871529579163 Train lndcg1_5 0.5579885840415955 Train lndcg1_10 0.6258955001831055 Train ndcg1_5 0.4307819902896881 Train ndcg1_10 0.5129837393760681 Train georisk_10 0.4446226954460144 Val ndcg_5 0.4055221676826477 Val ndcg_10 0.487227201461792 Val lndcg_5 0.5272372961044312 Val lndcg_10 0.597879946231842 Val lndcg1_5 0.5454049110412598 Val lndcg1_10 0.6160454154014587 Val ndcg1_5 0.42368942499160767 Val ndcg1_10 0.5053879618644714 Val georisk_10 0.4404445290565491
2023-08-10 17:13:13,787 - allrank.utils.ltr_logging - INFO - Current:0.487227201461792 Best:0.49079662561416626
2023-08-10 17:13:32,772 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 17:28:33,329 - allrank.utils.ltr_logging - INFO - Epoch : 9 Train loss: 0.21625321566776076 Val loss: 0.23079721996852007 Train ndcg_5 0.41718536615371704 Train ndcg_10 0.4981599748134613 Train lndcg_5 0.5287777781486511 Train lndcg_10 0.598290205001831 Train lndcg1_5 0.555125892162323 Train lndcg1_10 0.6238091588020325 Train ndcg1_5 0.43775367736816406 Train ndcg1_10 0.5199510455131531 Train georisk_10 0.4470134973526001 Val ndcg_5 0.4006686210632324 Val ndcg_10 0.48439982533454895 Val lndcg_5 0.5217317938804626 Val lndcg_10 0.5953128337860107 Val lndcg1_5 0.5399584770202637 Val lndcg1_10 0.6134880185127258 Val ndcg1_5 0.41887366771698 Val ndcg1_10 0.502543568611145 Val georisk_10 0.43933016061782837
2023-08-10 17:28:33,329 - allrank.utils.ltr_logging - INFO - Current:0.48439982533454895 Best:0.49079662561416626
2023-08-10 17:28:52,378 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 17:43:54,583 - allrank.utils.ltr_logging - INFO - Epoch : 10 Train loss: 0.2146262204242167 Val loss: 0.23029612058900167 Train ndcg_5 0.4251389801502228 Train ndcg_10 0.5009470582008362 Train lndcg_5 0.5381090044975281 Train lndcg_10 0.6048802137374878 Train lndcg1_5 0.5592729449272156 Train lndcg1_10 0.6254295706748962 Train ndcg1_5 0.43305709958076477 Train ndcg1_10 0.5164801478385925 Train georisk_10 0.44308966398239136 Val ndcg_5 0.3987632393836975 Val ndcg_10 0.4838237166404724 Val lndcg_5 0.5187876224517822 Val lndcg_10 0.5939818024635315 Val lndcg1_5 0.5370103716850281 Val lndcg1_10 0.6121562719345093 Val ndcg1_5 0.4169149398803711 Val ndcg1_10 0.5020025968551636 Val georisk_10 0.4392319619655609
2023-08-10 17:43:54,583 - allrank.utils.ltr_logging - INFO - Current:0.4838237166404724 Best:0.49079662561416626
2023-08-10 17:44:13,803 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 17:59:15,642 - allrank.utils.ltr_logging - INFO - Epoch : 11 Train loss: 0.21475675758592325 Val loss: 0.22989932561843504 Train ndcg_5 0.4142703711986542 Train ndcg_10 0.4946841895580292 Train lndcg_5 0.5301812291145325 Train lndcg_10 0.5988112688064575 Train lndcg1_5 0.5505759716033936 Train lndcg1_10 0.6232233047485352 Train ndcg1_5 0.4374465346336365 Train ndcg1_10 0.517193615436554 Train georisk_10 0.44760340452194214 Val ndcg_5 0.4028942286968231 Val ndcg_10 0.48303520679473877 Val lndcg_5 0.5239486694335938 Val lndcg_10 0.5942029356956482 Val lndcg1_5 0.542116105556488 Val lndcg1_10 0.6123703718185425 Val ndcg1_5 0.4210616946220398 Val ndcg1_10 0.5012024641036987 Val georisk_10 0.4390876889228821
2023-08-10 17:59:15,642 - allrank.utils.ltr_logging - INFO - Current:0.48303520679473877 Best:0.49079662561416626
2023-08-10 17:59:34,705 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 18:14:37,022 - allrank.utils.ltr_logging - INFO - Epoch : 12 Train loss: 0.21495114057361608 Val loss: 0.2300163444137498 Train ndcg_5 0.41464605927467346 Train ndcg_10 0.4972124397754669 Train lndcg_5 0.5374318361282349 Train lndcg_10 0.6055551171302795 Train lndcg1_5 0.5534726977348328 Train lndcg1_10 0.6207841634750366 Train ndcg1_5 0.44004637002944946 Train ndcg1_10 0.5226988792419434 Train georisk_10 0.4518449604511261 Val ndcg_5 0.4069089889526367 Val ndcg_10 0.48982375860214233 Val lndcg_5 0.5295352339744568 Val lndcg_10 0.6010808944702148 Val lndcg1_5 0.5477026700973511 Val lndcg1_10 0.6192484498023987 Val ndcg1_5 0.42507654428482056 Val ndcg1_10 0.5079913139343262 Val georisk_10 0.44308948516845703
2023-08-10 18:14:37,022 - allrank.utils.ltr_logging - INFO - Current:0.48982375860214233 Best:0.49079662561416626
2023-08-10 18:14:56,244 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 18:29:58,386 - allrank.utils.ltr_logging - INFO - Epoch : 13 Train loss: 0.21496432049767855 Val loss: 0.23034698853937183 Train ndcg_5 0.418731689453125 Train ndcg_10 0.5000640153884888 Train lndcg_5 0.534915566444397 Train lndcg_10 0.6028860211372375 Train lndcg1_5 0.5618232488632202 Train lndcg1_10 0.6287280321121216 Train ndcg1_5 0.4533027112483978 Train ndcg1_10 0.5309916138648987 Train georisk_10 0.44857633113861084 Val ndcg_5 0.42218297719955444 Val ndcg_10 0.5040907263755798 Val lndcg_5 0.5404152274131775 Val lndcg_10 0.6108558773994446 Val lndcg1_5 0.5585826635360718 Val lndcg1_10 0.6290233135223389 Val ndcg1_5 0.4403502941131592 Val ndcg1_10 0.5222580432891846 Val georisk_10 0.44987040758132935
2023-08-10 18:29:58,386 - allrank.utils.ltr_logging - INFO - Current:0.5040907263755798 Best:0.49079662561416626
2023-08-10 18:30:17,528 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.42059000564177446, 'ndcg_10': 0.5041931636721454, 'lndcg_5': 0.5394603640676235, 'lndcg_10': 0.6109533998561629, 'lndcg1_5': 0.5576278206237057, 'lndcg1_10': 0.6291208564122451, 'ndcg1_5': 0.4387574621978566, 'ndcg1_10': 0.5223606202282275} 
2023-08-10 18:30:17,528 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 18:45:21,191 - allrank.utils.ltr_logging - INFO - Epoch : 14 Train loss: 0.21510815361476435 Val loss: 0.23104591622925105 Train ndcg_5 0.4144337773323059 Train ndcg_10 0.49753814935684204 Train lndcg_5 0.5369532704353333 Train lndcg_10 0.6052797436714172 Train lndcg1_5 0.5584880113601685 Train lndcg1_10 0.6278988122940063 Train ndcg1_5 0.43520820140838623 Train ndcg1_10 0.5191314220428467 Train georisk_10 0.44806304574012756 Val ndcg_5 0.4285619258880615 Val ndcg_10 0.5104695558547974 Val lndcg_5 0.5437222123146057 Val lndcg_10 0.6136979460716248 Val lndcg1_5 0.5619540810585022 Val lndcg1_10 0.6319224834442139 Val ndcg1_5 0.44668054580688477 Val ndcg1_10 0.5286234021186829 Val georisk_10 0.4548680782318115
2023-08-10 18:45:21,191 - allrank.utils.ltr_logging - INFO - Current:0.5104695558547974 Best:0.5040907263755798
2023-08-10 18:45:40,207 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.42940211210603824, 'ndcg_10': 0.5126967421208384, 'lndcg_5': 0.544759226794147, 'lndcg_10': 0.6158248892801463, 'lndcg1_5': 0.5629266833502291, 'lndcg1_10': 0.6339923458362284, 'ndcg1_5': 0.4475695686621204, 'ndcg1_10': 0.5308641986769205} 
2023-08-10 18:45:40,207 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 19:00:42,616 - allrank.utils.ltr_logging - INFO - Epoch : 15 Train loss: 0.21522779395512495 Val loss: 0.23133036995668546 Train ndcg_5 0.41999030113220215 Train ndcg_10 0.497079998254776 Train lndcg_5 0.5314213633537292 Train lndcg_10 0.6012205481529236 Train lndcg1_5 0.5528265833854675 Train lndcg1_10 0.6233859658241272 Train ndcg1_5 0.4459650218486786 Train ndcg1_10 0.5290863513946533 Train georisk_10 0.4494440257549286 Val ndcg_5 0.421906977891922 Val ndcg_10 0.5040196180343628 Val lndcg_5 0.5396751761436462 Val lndcg_10 0.6097568869590759 Val lndcg1_5 0.557805061340332 Val lndcg1_10 0.6278567314147949 Val ndcg1_5 0.4399910271167755 Val ndcg1_10 0.5221421122550964 Val georisk_10 0.4500247836112976
2023-08-10 19:00:42,632 - allrank.utils.ltr_logging - INFO - Current:0.5040196180343628 Best:0.5104695558547974
2023-08-10 19:01:01,867 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 19:16:03,345 - allrank.utils.ltr_logging - INFO - Epoch : 16 Train loss: 0.21515923324166128 Val loss: 0.2302303134830077 Train ndcg_5 0.4177720844745636 Train ndcg_10 0.4954661726951599 Train lndcg_5 0.5228571891784668 Train lndcg_10 0.596812903881073 Train lndcg1_5 0.5546465516090393 Train lndcg1_10 0.6246036887168884 Train ndcg1_5 0.4333769381046295 Train ndcg1_10 0.5175414085388184 Train georisk_10 0.4487648606300354 Val ndcg_5 0.42476627230644226 Val ndcg_10 0.5066701769828796 Val lndcg_5 0.5424608588218689 Val lndcg_10 0.6124629378318787 Val lndcg1_5 0.5607894659042358 Val lndcg1_10 0.6308299899101257 Val ndcg1_5 0.44292059540748596 Val ndcg1_10 0.5247877240180969 Val georisk_10 0.4529305100440979
2023-08-10 19:16:03,345 - allrank.utils.ltr_logging - INFO - Current:0.5066701769828796 Best:0.5104695558547974
2023-08-10 19:16:22,128 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 19:31:24,565 - allrank.utils.ltr_logging - INFO - Epoch : 17 Train loss: 0.21487926014980058 Val loss: 0.22994784184541747 Train ndcg_5 0.4119311273097992 Train ndcg_10 0.4937032461166382 Train lndcg_5 0.5334529876708984 Train lndcg_10 0.6037687063217163 Train lndcg1_5 0.5515967607498169 Train lndcg1_10 0.6224798560142517 Train ndcg1_5 0.4420958459377289 Train ndcg1_10 0.522686243057251 Train georisk_10 0.44665423035621643 Val ndcg_5 0.4194054901599884 Val ndcg_10 0.49926358461380005 Val lndcg_5 0.5386717319488525 Val lndcg_10 0.6073242425918579 Val lndcg1_5 0.5567226409912109 Val lndcg1_10 0.6255052089691162 Val ndcg1_5 0.4375945031642914 Val ndcg1_10 0.5174210667610168 Val georisk_10 0.44702863693237305
2023-08-10 19:31:24,565 - allrank.utils.ltr_logging - INFO - Current:0.49926358461380005 Best:0.5104695558547974
2023-08-10 19:31:43,799 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 19:46:45,775 - allrank.utils.ltr_logging - INFO - Epoch : 18 Train loss: 0.2144324923578597 Val loss: 0.23195179644824956 Train ndcg_5 0.43180233240127563 Train ndcg_10 0.5082150101661682 Train lndcg_5 0.534896731376648 Train lndcg_10 0.6038158535957336 Train lndcg1_5 0.5560992360115051 Train lndcg1_10 0.6257222294807434 Train ndcg1_5 0.44028347730636597 Train ndcg1_10 0.5215399861335754 Train georisk_10 0.44585689902305603 Val ndcg_5 0.42869436740875244 Val ndcg_10 0.509611189365387 Val lndcg_5 0.5445235967636108 Val lndcg_10 0.6137797832489014 Val lndcg1_5 0.5630421042442322 Val lndcg1_10 0.6322453022003174 Val ndcg1_5 0.4468730092048645 Val ndcg1_10 0.5277106165885925 Val georisk_10 0.4540277123451233
2023-08-10 19:46:45,775 - allrank.utils.ltr_logging - INFO - Current:0.509611189365387 Best:0.5104695558547974
2023-08-10 19:47:04,840 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 20:02:06,632 - allrank.utils.ltr_logging - INFO - Epoch : 19 Train loss: 0.21492745822639828 Val loss: 0.23010233235302693 Train ndcg_5 0.4228917360305786 Train ndcg_10 0.5049591064453125 Train lndcg_5 0.5357580780982971 Train lndcg_10 0.6040148735046387 Train lndcg1_5 0.5496231317520142 Train lndcg1_10 0.6216972470283508 Train ndcg1_5 0.4471590220928192 Train ndcg1_10 0.5293444395065308 Train georisk_10 0.4512872099876404 Val ndcg_5 0.4364161789417267 Val ndcg_10 0.5180270075798035 Val lndcg_5 0.5506430268287659 Val lndcg_10 0.62074875831604 Val lndcg1_5 0.5688732862472534 Val lndcg1_10 0.6390329599380493 Val ndcg1_5 0.4548477828502655 Val ndcg1_10 0.5364160537719727 Val georisk_10 0.4584031403064728
2023-08-10 20:02:06,632 - allrank.utils.ltr_logging - INFO - Current:0.5180270075798035 Best:0.5104695558547974
2023-08-10 20:02:25,679 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.44087130804275626, 'ndcg_10': 0.5208547584227076, 'lndcg_5': 0.5546403239758347, 'lndcg_10': 0.623436888312499, 'lndcg1_5': 0.5728077805319169, 'lndcg1_10': 0.6416043448685811, 'ndcg1_5': 0.4590387645988384, 'ndcg1_10': 0.5390222149787897} 
2023-08-10 20:02:25,679 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 20:17:26,809 - allrank.utils.ltr_logging - INFO - Epoch : 20 Train loss: 0.2144632251906734 Val loss: 0.2299124939605523 Train ndcg_5 0.4176959693431854 Train ndcg_10 0.4996815323829651 Train lndcg_5 0.5438565015792847 Train lndcg_10 0.6101966500282288 Train lndcg1_5 0.5623241662979126 Train lndcg1_10 0.6289507150650024 Train ndcg1_5 0.44057148694992065 Train ndcg1_10 0.5201167464256287 Train georisk_10 0.44918176531791687 Val ndcg_5 0.4280106723308563 Val ndcg_10 0.5098345875740051 Val lndcg_5 0.5444939732551575 Val lndcg_10 0.6154208779335022 Val lndcg1_5 0.5628765821456909 Val lndcg1_10 0.633689284324646 Val ndcg1_5 0.44609129428863525 Val ndcg1_10 0.5279790163040161 Val georisk_10 0.4535728394985199
2023-08-10 20:17:26,809 - allrank.utils.ltr_logging - INFO - Current:0.5098345875740051 Best:0.5180270075798035
2023-08-10 20:17:45,762 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 20:32:50,782 - allrank.utils.ltr_logging - INFO - Epoch : 21 Train loss: 0.21404452290015197 Val loss: 0.22987129585155378 Train ndcg_5 0.42256614565849304 Train ndcg_10 0.503923773765564 Train lndcg_5 0.5348849296569824 Train lndcg_10 0.6039266586303711 Train lndcg1_5 0.555535614490509 Train lndcg1_10 0.6271079778671265 Train ndcg1_5 0.4435417056083679 Train ndcg1_10 0.5239637494087219 Train georisk_10 0.45029985904693604 Val ndcg_5 0.4211626946926117 Val ndcg_10 0.5039495229721069 Val lndcg_5 0.5370033979415894 Val lndcg_10 0.6096329689025879 Val lndcg1_5 0.5553795695304871 Val lndcg1_10 0.6280055046081543 Val ndcg1_5 0.4393745958805084 Val ndcg1_10 0.5221562385559082 Val georisk_10 0.44869983196258545
2023-08-10 20:32:50,782 - allrank.utils.ltr_logging - INFO - Current:0.5039495229721069 Best:0.5180270075798035
2023-08-10 20:33:09,705 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 20:48:11,841 - allrank.utils.ltr_logging - INFO - Epoch : 22 Train loss: 0.215212488720579 Val loss: 0.2312812615439037 Train ndcg_5 0.41795533895492554 Train ndcg_10 0.49917399883270264 Train lndcg_5 0.5374452471733093 Train lndcg_10 0.6065123677253723 Train lndcg1_5 0.5608020424842834 Train lndcg1_10 0.6273890733718872 Train ndcg1_5 0.4328126311302185 Train ndcg1_10 0.5187273025512695 Train georisk_10 0.4482960104942322 Val ndcg_5 0.42590901255607605 Val ndcg_10 0.5086519122123718 Val lndcg_5 0.5413294434547424 Val lndcg_10 0.6125504970550537 Val lndcg1_5 0.5595586895942688 Val lndcg1_10 0.6308436393737793 Val ndcg1_5 0.44397860765457153 Val ndcg1_10 0.5267422199249268 Val georisk_10 0.453757643699646
2023-08-10 20:48:11,841 - allrank.utils.ltr_logging - INFO - Current:0.5086519122123718 Best:0.5180270075798035
2023-08-10 20:48:30,906 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 21:03:33,549 - allrank.utils.ltr_logging - INFO - Epoch : 23 Train loss: 0.21438622437005547 Val loss: 0.2326372444017615 Train ndcg_5 0.4218156635761261 Train ndcg_10 0.5003777742385864 Train lndcg_5 0.5304760932922363 Train lndcg_10 0.601319432258606 Train lndcg1_5 0.5540546774864197 Train lndcg1_10 0.6240237951278687 Train ndcg1_5 0.4475051760673523 Train ndcg1_10 0.5229948163032532 Train georisk_10 0.45314455032348633 Val ndcg_5 0.4271826446056366 Val ndcg_10 0.5094310641288757 Val lndcg_5 0.5420965552330017 Val lndcg_10 0.6133766174316406 Val lndcg1_5 0.5602641701698303 Val lndcg1_10 0.6315460205078125 Val ndcg1_5 0.44542646408081055 Val ndcg1_10 0.5276365280151367 Val georisk_10 0.45270633697509766
2023-08-10 21:03:33,549 - allrank.utils.ltr_logging - INFO - Current:0.5094310641288757 Best:0.5180270075798035
2023-08-10 21:03:52,457 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 21:18:55,137 - allrank.utils.ltr_logging - INFO - Epoch : 24 Train loss: 0.2147034966456005 Val loss: 0.23050451417575704 Train ndcg_5 0.4174399673938751 Train ndcg_10 0.5013027191162109 Train lndcg_5 0.5378515720367432 Train lndcg_10 0.6065928936004639 Train lndcg1_5 0.5600415468215942 Train lndcg1_10 0.6274667978286743 Train ndcg1_5 0.4397641718387604 Train ndcg1_10 0.5203213095664978 Train georisk_10 0.4492228329181671 Val ndcg_5 0.4141407907009125 Val ndcg_10 0.4942927658557892 Val lndcg_5 0.5319393277168274 Val lndcg_10 0.6024435758590698 Val lndcg1_5 0.5501092672348022 Val lndcg1_10 0.620685338973999 Val ndcg1_5 0.4323401153087616 Val ndcg1_10 0.5124563574790955 Val georisk_10 0.4438540041446686
2023-08-10 21:18:55,137 - allrank.utils.ltr_logging - INFO - Current:0.4942927658557892 Best:0.5180270075798035
2023-08-10 21:19:14,077 - allrank.utils.ltr_logging - INFO - Ending execution. Train Losses:
[0.2747219307774804, 0.22078264343418405, 0.2173021981878115, 0.21712595066658882, 0.21683553153116367, 0.21460890551031483, 0.21651509997404017, 0.2149684910572724, 0.2154245127998822, 0.21625321566776076, 0.2146262204242167, 0.21475675758592325, 0.21495114057361608, 0.21496432049767855, 0.21510815361476435, 0.21522779395512495, 0.21515923324166128, 0.21487926014980058, 0.2144324923578597, 0.21492745822639828, 0.2144632251906734, 0.21404452290015197, 0.215212488720579, 0.21438622437005547, 0.2147034966456005]
2023-08-10 21:19:14,077 - allrank.utils.ltr_logging - INFO - Ending execution. Validation Losses (not used to train):
[0.23275271091039335, 0.23075140704287547, 0.23072186870409225, 0.2304618930882564, 0.23048567651854873, 0.23022031400346832, 0.2303058583212878, 0.23035944155513016, 0.23006763279814668, 0.23079721996852007, 0.23029612058900167, 0.22989932561843504, 0.2300163444137498, 0.23034698853937183, 0.23104591622925105, 0.23133036995668546, 0.2302303134830077, 0.22994784184541747, 0.23195179644824956, 0.23010233235302693, 0.2299124939605523, 0.22987129585155378, 0.2312812615439037, 0.2326372444017615, 0.23050451417575704]
2023-08-10 21:19:14,077 - allrank.utils.ltr_logging - INFO - Ending execution. Train Metrics Evolution:
[{'ndcg_5': 0.41963163, 'ndcg_10': 0.5000849, 'lndcg_5': 0.5343219, 'lndcg_10': 0.60278696, 'lndcg1_5': 0.5507749, 'lndcg1_10': 0.6200682, 'ndcg1_5': 0.4355158, 'ndcg1_10': 0.5151742, 'georisk_10': 0.4488845}, {'ndcg_5': 0.40810525, 'ndcg_10': 0.48666343, 'lndcg_5': 0.52778345, 'lndcg_10': 0.6001311, 'lndcg1_5': 0.54792386, 'lndcg1_10': 0.62127143, 'ndcg1_5': 0.43414235, 'ndcg1_10': 0.5130478, 'georisk_10': 0.44451368}, {'ndcg_5': 0.4146429, 'ndcg_10': 0.49405828, 'lndcg_5': 0.52938527, 'lndcg_10': 0.59932417, 'lndcg1_5': 0.5475097, 'lndcg1_10': 0.61693686, 'ndcg1_5': 0.4339118, 'ndcg1_10': 0.5145646, 'georisk_10': 0.4411529}, {'ndcg_5': 0.4155143, 'ndcg_10': 0.49327004, 'lndcg_5': 0.53068817, 'lndcg_10': 0.599124, 'lndcg1_5': 0.55359644, 'lndcg1_10': 0.6226922, 'ndcg1_5': 0.4353794, 'ndcg1_10': 0.5183036, 'georisk_10': 0.443833}, {'ndcg_5': 0.41402036, 'ndcg_10': 0.49707353, 'lndcg_5': 0.53094333, 'lndcg_10': 0.60233194, 'lndcg1_5': 0.5577659, 'lndcg1_10': 0.6274681, 'ndcg1_5': 0.43949714, 'ndcg1_10': 0.5179311, 'georisk_10': 0.44470906}, {'ndcg_5': 0.40614766, 'ndcg_10': 0.48785332, 'lndcg_5': 0.52314675, 'lndcg_10': 0.596989, 'lndcg1_5': 0.55131936, 'lndcg1_10': 0.623475, 'ndcg1_5': 0.43530712, 'ndcg1_10': 0.5151981, 'georisk_10': 0.44545949}, {'ndcg_5': 0.41079408, 'ndcg_10': 0.4910834, 'lndcg_5': 0.5322885, 'lndcg_10': 0.60122716, 'lndcg1_5': 0.54535013, 'lndcg1_10': 0.6179276, 'ndcg1_5': 0.43134776, 'ndcg1_10': 0.5139933, 'georisk_10': 0.44787452}, {'ndcg_5': 0.41910538, 'ndcg_10': 0.4981635, 'lndcg_5': 0.5266914, 'lndcg_10': 0.5998911, 'lndcg1_5': 0.54857475, 'lndcg1_10': 0.6208124, 'ndcg1_5': 0.44199958, 'ndcg1_10': 0.51877725, 'georisk_10': 0.44461632}, {'ndcg_5': 0.4124646, 'ndcg_10': 0.49919444, 'lndcg_5': 0.5314171, 'lndcg_10': 0.60108715, 'lndcg1_5': 0.5579886, 'lndcg1_10': 0.6258955, 'ndcg1_5': 0.430782, 'ndcg1_10': 0.51298374, 'georisk_10': 0.4446227}, {'ndcg_5': 0.41718537, 'ndcg_10': 0.49815997, 'lndcg_5': 0.5287778, 'lndcg_10': 0.5982902, 'lndcg1_5': 0.5551259, 'lndcg1_10': 0.62380916, 'ndcg1_5': 0.43775368, 'ndcg1_10': 0.51995105, 'georisk_10': 0.4470135}, {'ndcg_5': 0.42513898, 'ndcg_10': 0.50094706, 'lndcg_5': 0.538109, 'lndcg_10': 0.6048802, 'lndcg1_5': 0.55927294, 'lndcg1_10': 0.6254296, 'ndcg1_5': 0.4330571, 'ndcg1_10': 0.51648015, 'georisk_10': 0.44308966}, {'ndcg_5': 0.41427037, 'ndcg_10': 0.4946842, 'lndcg_5': 0.5301812, 'lndcg_10': 0.59881127, 'lndcg1_5': 0.550576, 'lndcg1_10': 0.6232233, 'ndcg1_5': 0.43744653, 'ndcg1_10': 0.5171936, 'georisk_10': 0.4476034}, {'ndcg_5': 0.41464606, 'ndcg_10': 0.49721244, 'lndcg_5': 0.53743184, 'lndcg_10': 0.6055551, 'lndcg1_5': 0.5534727, 'lndcg1_10': 0.62078416, 'ndcg1_5': 0.44004637, 'ndcg1_10': 0.5226989, 'georisk_10': 0.45184496}, {'ndcg_5': 0.4187317, 'ndcg_10': 0.500064, 'lndcg_5': 0.53491557, 'lndcg_10': 0.602886, 'lndcg1_5': 0.56182325, 'lndcg1_10': 0.62872803, 'ndcg1_5': 0.4533027, 'ndcg1_10': 0.5309916, 'georisk_10': 0.44857633}, {'ndcg_5': 0.41443378, 'ndcg_10': 0.49753815, 'lndcg_5': 0.5369533, 'lndcg_10': 0.60527974, 'lndcg1_5': 0.558488, 'lndcg1_10': 0.6278988, 'ndcg1_5': 0.4352082, 'ndcg1_10': 0.5191314, 'georisk_10': 0.44806305}, {'ndcg_5': 0.4199903, 'ndcg_10': 0.49708, 'lndcg_5': 0.53142136, 'lndcg_10': 0.60122055, 'lndcg1_5': 0.5528266, 'lndcg1_10': 0.62338597, 'ndcg1_5': 0.44596502, 'ndcg1_10': 0.52908635, 'georisk_10': 0.44944403}, {'ndcg_5': 0.41777208, 'ndcg_10': 0.49546617, 'lndcg_5': 0.5228572, 'lndcg_10': 0.5968129, 'lndcg1_5': 0.55464655, 'lndcg1_10': 0.6246037, 'ndcg1_5': 0.43337694, 'ndcg1_10': 0.5175414, 'georisk_10': 0.44876486}, {'ndcg_5': 0.41193113, 'ndcg_10': 0.49370325, 'lndcg_5': 0.533453, 'lndcg_10': 0.6037687, 'lndcg1_5': 0.55159676, 'lndcg1_10': 0.62247986, 'ndcg1_5': 0.44209585, 'ndcg1_10': 0.52268624, 'georisk_10': 0.44665423}, {'ndcg_5': 0.43180233, 'ndcg_10': 0.508215, 'lndcg_5': 0.53489673, 'lndcg_10': 0.60381585, 'lndcg1_5': 0.55609924, 'lndcg1_10': 0.6257222, 'ndcg1_5': 0.44028348, 'ndcg1_10': 0.52154, 'georisk_10': 0.4458569}, {'ndcg_5': 0.42289174, 'ndcg_10': 0.5049591, 'lndcg_5': 0.5357581, 'lndcg_10': 0.6040149, 'lndcg1_5': 0.54962313, 'lndcg1_10': 0.62169725, 'ndcg1_5': 0.44715902, 'ndcg1_10': 0.52934444, 'georisk_10': 0.4512872}, {'ndcg_5': 0.41769597, 'ndcg_10': 0.49968153, 'lndcg_5': 0.5438565, 'lndcg_10': 0.61019665, 'lndcg1_5': 0.56232417, 'lndcg1_10': 0.6289507, 'ndcg1_5': 0.4405715, 'ndcg1_10': 0.52011675, 'georisk_10': 0.44918177}, {'ndcg_5': 0.42256615, 'ndcg_10': 0.5039238, 'lndcg_5': 0.5348849, 'lndcg_10': 0.60392666, 'lndcg1_5': 0.5555356, 'lndcg1_10': 0.627108, 'ndcg1_5': 0.4435417, 'ndcg1_10': 0.52396375, 'georisk_10': 0.45029986}, {'ndcg_5': 0.41795534, 'ndcg_10': 0.499174, 'lndcg_5': 0.53744525, 'lndcg_10': 0.60651237, 'lndcg1_5': 0.56080204, 'lndcg1_10': 0.6273891, 'ndcg1_5': 0.43281263, 'ndcg1_10': 0.5187273, 'georisk_10': 0.448296}, {'ndcg_5': 0.42181566, 'ndcg_10': 0.5003778, 'lndcg_5': 0.5304761, 'lndcg_10': 0.60131943, 'lndcg1_5': 0.5540547, 'lndcg1_10': 0.6240238, 'ndcg1_5': 0.44750518, 'ndcg1_10': 0.5229948, 'georisk_10': 0.45314455}, {'ndcg_5': 0.41743997, 'ndcg_10': 0.5013027, 'lndcg_5': 0.5378516, 'lndcg_10': 0.6065929, 'lndcg1_5': 0.56004155, 'lndcg1_10': 0.6274668, 'ndcg1_5': 0.43976417, 'ndcg1_10': 0.5203213, 'georisk_10': 0.44922283}]
2023-08-10 21:19:14,093 - allrank.utils.ltr_logging - INFO - Ending execution. Validation Metrics Evolution:
[{'ndcg_5': 0.40791386, 'ndcg_10': 0.49079663, 'lndcg_5': 0.5284557, 'lndcg_10': 0.6011631, 'lndcg1_5': 0.546623, 'lndcg1_10': 0.6193305, 'ndcg1_5': 0.42608127, 'ndcg1_10': 0.5089641, 'georisk_10': 0.44015974}, {'ndcg_5': 0.40111598, 'ndcg_10': 0.48168144, 'lndcg_5': 0.5234182, 'lndcg_10': 0.5943129, 'lndcg1_5': 0.54158574, 'lndcg1_10': 0.6124804, 'ndcg1_5': 0.41928327, 'ndcg1_10': 0.49984905, 'georisk_10': 0.4358261}, {'ndcg_5': 0.39563233, 'ndcg_10': 0.4778158, 'lndcg_5': 0.5186901, 'lndcg_10': 0.5909009, 'lndcg1_5': 0.5368575, 'lndcg1_10': 0.60906833, 'ndcg1_5': 0.41379964, 'ndcg1_10': 0.4959834, 'georisk_10': 0.43414935}, {'ndcg_5': 0.39512277, 'ndcg_10': 0.47652853, 'lndcg_5': 0.51871645, 'lndcg_10': 0.59021145, 'lndcg1_5': 0.5368839, 'lndcg1_10': 0.6083789, 'ndcg1_5': 0.4132903, 'ndcg1_10': 0.49469605, 'georisk_10': 0.433125}, {'ndcg_5': 0.3978996, 'ndcg_10': 0.4787607, 'lndcg_5': 0.52093476, 'lndcg_10': 0.59142447, 'lndcg1_5': 0.5391211, 'lndcg1_10': 0.60960495, 'ndcg1_5': 0.4160541, 'ndcg1_10': 0.49691522, 'georisk_10': 0.43398517}, {'ndcg_5': 0.3982273, 'ndcg_10': 0.4799943, 'lndcg_5': 0.52213776, 'lndcg_10': 0.5932217, 'lndcg1_5': 0.54030526, 'lndcg1_10': 0.6113891, 'ndcg1_5': 0.41639477, 'ndcg1_10': 0.4981619, 'georisk_10': 0.4360405}, {'ndcg_5': 0.3954635, 'ndcg_10': 0.47826344, 'lndcg_5': 0.5183798, 'lndcg_10': 0.5910356, 'lndcg1_5': 0.53654724, 'lndcg1_10': 0.609203, 'ndcg1_5': 0.4136309, 'ndcg1_10': 0.4964281, 'georisk_10': 0.43520135}, {'ndcg_5': 0.3981626, 'ndcg_10': 0.48121294, 'lndcg_5': 0.52076894, 'lndcg_10': 0.59362525, 'lndcg1_5': 0.5389364, 'lndcg1_10': 0.6117952, 'ndcg1_5': 0.41632986, 'ndcg1_10': 0.49938223, 'georisk_10': 0.43719673}, {'ndcg_5': 0.40552217, 'ndcg_10': 0.4872272, 'lndcg_5': 0.5272373, 'lndcg_10': 0.59787995, 'lndcg1_5': 0.5454049, 'lndcg1_10': 0.6160454, 'ndcg1_5': 0.42368942, 'ndcg1_10': 0.50538796, 'georisk_10': 0.44044453}, {'ndcg_5': 0.40066862, 'ndcg_10': 0.48439983, 'lndcg_5': 0.5217318, 'lndcg_10': 0.59531283, 'lndcg1_5': 0.5399585, 'lndcg1_10': 0.613488, 'ndcg1_5': 0.41887367, 'ndcg1_10': 0.50254357, 'georisk_10': 0.43933016}, {'ndcg_5': 0.39876324, 'ndcg_10': 0.48382372, 'lndcg_5': 0.5187876, 'lndcg_10': 0.5939818, 'lndcg1_5': 0.5370104, 'lndcg1_10': 0.6121563, 'ndcg1_5': 0.41691494, 'ndcg1_10': 0.5020026, 'georisk_10': 0.43923196}, {'ndcg_5': 0.40289423, 'ndcg_10': 0.4830352, 'lndcg_5': 0.52394867, 'lndcg_10': 0.59420294, 'lndcg1_5': 0.5421161, 'lndcg1_10': 0.6123704, 'ndcg1_5': 0.4210617, 'ndcg1_10': 0.50120246, 'georisk_10': 0.4390877}, {'ndcg_5': 0.406909, 'ndcg_10': 0.48982376, 'lndcg_5': 0.52953523, 'lndcg_10': 0.6010809, 'lndcg1_5': 0.54770267, 'lndcg1_10': 0.61924845, 'ndcg1_5': 0.42507654, 'ndcg1_10': 0.5079913, 'georisk_10': 0.4430895}, {'ndcg_5': 0.42218298, 'ndcg_10': 0.5040907, 'lndcg_5': 0.5404152, 'lndcg_10': 0.6108559, 'lndcg1_5': 0.55858266, 'lndcg1_10': 0.6290233, 'ndcg1_5': 0.4403503, 'ndcg1_10': 0.52225804, 'georisk_10': 0.4498704}, {'ndcg_5': 0.42856193, 'ndcg_10': 0.51046956, 'lndcg_5': 0.5437222, 'lndcg_10': 0.61369795, 'lndcg1_5': 0.5619541, 'lndcg1_10': 0.6319225, 'ndcg1_5': 0.44668055, 'ndcg1_10': 0.5286234, 'georisk_10': 0.45486808}, {'ndcg_5': 0.42190698, 'ndcg_10': 0.5040196, 'lndcg_5': 0.5396752, 'lndcg_10': 0.6097569, 'lndcg1_5': 0.55780506, 'lndcg1_10': 0.62785673, 'ndcg1_5': 0.43999103, 'ndcg1_10': 0.5221421, 'georisk_10': 0.45002478}, {'ndcg_5': 0.42476627, 'ndcg_10': 0.5066702, 'lndcg_5': 0.54246086, 'lndcg_10': 0.61246294, 'lndcg1_5': 0.56078947, 'lndcg1_10': 0.63083, 'ndcg1_5': 0.4429206, 'ndcg1_10': 0.5247877, 'georisk_10': 0.4529305}, {'ndcg_5': 0.4194055, 'ndcg_10': 0.49926358, 'lndcg_5': 0.53867173, 'lndcg_10': 0.60732424, 'lndcg1_5': 0.55672264, 'lndcg1_10': 0.6255052, 'ndcg1_5': 0.4375945, 'ndcg1_10': 0.51742107, 'georisk_10': 0.44702864}, {'ndcg_5': 0.42869437, 'ndcg_10': 0.5096112, 'lndcg_5': 0.5445236, 'lndcg_10': 0.6137798, 'lndcg1_5': 0.5630421, 'lndcg1_10': 0.6322453, 'ndcg1_5': 0.446873, 'ndcg1_10': 0.5277106, 'georisk_10': 0.4540277}, {'ndcg_5': 0.43641618, 'ndcg_10': 0.518027, 'lndcg_5': 0.550643, 'lndcg_10': 0.62074876, 'lndcg1_5': 0.5688733, 'lndcg1_10': 0.63903296, 'ndcg1_5': 0.45484778, 'ndcg1_10': 0.53641605, 'georisk_10': 0.45840314}, {'ndcg_5': 0.42801067, 'ndcg_10': 0.5098346, 'lndcg_5': 0.544494, 'lndcg_10': 0.6154209, 'lndcg1_5': 0.5628766, 'lndcg1_10': 0.6336893, 'ndcg1_5': 0.4460913, 'ndcg1_10': 0.527979, 'georisk_10': 0.45357284}, {'ndcg_5': 0.4211627, 'ndcg_10': 0.5039495, 'lndcg_5': 0.5370034, 'lndcg_10': 0.60963297, 'lndcg1_5': 0.55537957, 'lndcg1_10': 0.6280055, 'ndcg1_5': 0.4393746, 'ndcg1_10': 0.52215624, 'georisk_10': 0.44869983}, {'ndcg_5': 0.425909, 'ndcg_10': 0.5086519, 'lndcg_5': 0.54132944, 'lndcg_10': 0.6125505, 'lndcg1_5': 0.5595587, 'lndcg1_10': 0.63084364, 'ndcg1_5': 0.4439786, 'ndcg1_10': 0.5267422, 'georisk_10': 0.45375764}, {'ndcg_5': 0.42718264, 'ndcg_10': 0.50943106, 'lndcg_5': 0.54209656, 'lndcg_10': 0.6133766, 'lndcg1_5': 0.56026417, 'lndcg1_10': 0.631546, 'ndcg1_5': 0.44542646, 'ndcg1_10': 0.5276365, 'georisk_10': 0.45270634}, {'ndcg_5': 0.4141408, 'ndcg_10': 0.49429277, 'lndcg_5': 0.5319393, 'lndcg_10': 0.6024436, 'lndcg1_5': 0.55010927, 'lndcg1_10': 0.62068534, 'ndcg1_5': 0.43234012, 'ndcg1_10': 0.51245636, 'georisk_10': 0.443854}]
2023-08-10 21:19:14,108 - allrank.utils.ltr_logging - INFO - Ending execution. Test Metrics Evolution:
[{'ndcg_5': 0.4079063522475752, 'ndcg_10': 0.4907767410632243, 'lndcg_5': 0.5284446777850241, 'lndcg_10': 0.6011378412779609, 'lndcg1_5': 0.5466121343411063, 'lndcg1_10': 0.619305297834043, 'ndcg1_5': 0.42607380880365736, 'ndcg1_10': 0.5089441976193064}, {'ndcg_5': 0.42059000564177446, 'ndcg_10': 0.5041931636721454, 'lndcg_5': 0.5394603640676235, 'lndcg_10': 0.6109533998561629, 'lndcg1_5': 0.5576278206237057, 'lndcg1_10': 0.6291208564122451, 'ndcg1_5': 0.4387574621978566, 'ndcg1_10': 0.5223606202282275}, {'ndcg_5': 0.42940211210603824, 'ndcg_10': 0.5126967421208384, 'lndcg_5': 0.544759226794147, 'lndcg_10': 0.6158248892801463, 'lndcg1_5': 0.5629266833502291, 'lndcg1_10': 0.6339923458362284, 'ndcg1_5': 0.4475695686621204, 'ndcg1_10': 0.5308641986769205}, {'ndcg_5': 0.44087130804275626, 'ndcg_10': 0.5208547584227076, 'lndcg_5': 0.5546403239758347, 'lndcg_10': 0.623436888312499, 'lndcg1_5': 0.5728077805319169, 'lndcg1_10': 0.6416043448685811, 'ndcg1_5': 0.4590387645988384, 'ndcg1_10': 0.5390222149787897}]
