2023-08-09 18:51:09,740 - allrank.utils.ltr_logging - INFO - created paths container PathsContainer(local_base_output_path='results-new/', base_output_path='results-new/', output_dir='results-new/results\\analiseweb10k', tensorboard_output_path='results-new/tb_evals\\single\\analiseweb10k', config_path='localtemp_config.json')
2023-08-09 18:51:09,741 - allrank.utils.ltr_logging - INFO - Config:
 {'click_model': None,
 'data': DataConfig(path='D:\\Colecoes\\BD\\web10k-norm\\Fold1', num_workers=0, batch_size=20, slate_length=100, validation_ds_role='vali'),
 'detect_anomaly': True,
 'expected_metrics': {'val': {'georisk_10': 0.0,
                              'lndcg_10': 0.0,
                              'lndcg_5': 0.0,
                              'ndcg_10': 0.0,
                              'ndcg_5': 0.0}},
 'loss': NameArgsConfig(name='geoRiskSpearmanLoss', args={}),
 'lr_scheduler': NameArgsConfig(name=None, args={'step_size': 800, 'gamma': 0.5}),
 'metrics': defaultdict(<class 'list'>,
                        {'georisk': [10],
                         'lndcg': [5,
                                   10],
                         'lndcg1': [5,
                                    10],
                         'ndcg': [5,
                                  10],
                         'ndcg1': [5,
                                   10]}),
 'model': ModelConfig(fc_model={}, transformer=TransformerConfig(N=2, d_ff=32, h=2, positional_encoding=None, dropout=0.3), post_model={'output_activation': 'Sigmoid', 'd_output': 1}),
 'optimizer': NameArgsConfig(name='Adam', args={'lr': 0.0001}),
 'training': TrainingConfig(epochs=50, gradient_clipping_norm=None, early_stopping_patience=100),
 'val_metric': 'ndcg_10'}
2023-08-09 18:51:09,742 - allrank.utils.ltr_logging - INFO - will execute copy "localtemp_config.json" "results-new/results\analiseweb10k\used_config.json"
2023-08-09 18:51:09,752 - allrank.utils.ltr_logging - INFO - exit_code = 0
2023-08-09 18:51:09,753 - allrank.utils.ltr_logging - INFO - will load train data from D:\Colecoes\BD\web10k-norm\Fold1\Norm.train.txt
2023-08-09 18:51:37,808 - allrank.utils.ltr_logging - INFO - loaded dataset from <_io.BufferedReader name='D:\\Colecoes\\BD\\web10k-norm\\Fold1\\Norm.train.txt'> and got x shape (351100, 136), y shape (351100,) and query_ids shape (351100,)
2023-08-09 18:51:38,113 - allrank.utils.ltr_logging - INFO - loaded dataset with 3511 queries
2023-08-09 18:51:38,114 - allrank.utils.ltr_logging - INFO - longest query had 100 documents
2023-08-09 18:51:38,200 - allrank.utils.ltr_logging - INFO - train DS shape: [3511, 100, 136]
2023-08-09 18:51:38,200 - allrank.utils.ltr_logging - INFO - will load vali data from D:\Colecoes\BD\web10k-norm\Fold1\Norm.vali.txt
2023-08-09 18:51:47,034 - allrank.utils.ltr_logging - INFO - loaded dataset from <_io.BufferedReader name='D:\\Colecoes\\BD\\web10k-norm\\Fold1\\Norm.vali.txt'> and got x shape (112000, 136), y shape (112000,) and query_ids shape (112000,)
2023-08-09 18:51:47,129 - allrank.utils.ltr_logging - INFO - loaded dataset with 1120 queries
2023-08-09 18:51:47,129 - allrank.utils.ltr_logging - INFO - longest query had 100 documents
2023-08-09 18:51:47,161 - allrank.utils.ltr_logging - INFO - vali DS shape: [1120, 100, 136]
2023-08-09 18:51:47,161 - allrank.utils.ltr_logging - INFO - Will pad to the longest slate: 100
2023-08-09 18:51:47,161 - allrank.utils.ltr_logging - INFO - will load test data from D:\Colecoes\BD\web10k-norm\Fold1\Norm.test.txt
2023-08-09 18:51:56,046 - allrank.utils.ltr_logging - INFO - loaded dataset from <_io.BufferedReader name='D:\\Colecoes\\BD\\web10k-norm\\Fold1\\Norm.test.txt'> and got x shape (113300, 136), y shape (113300,) and query_ids shape (113300,)
2023-08-09 18:51:56,143 - allrank.utils.ltr_logging - INFO - loaded dataset with 1133 queries
2023-08-09 18:51:56,143 - allrank.utils.ltr_logging - INFO - longest query had 100 documents
2023-08-09 18:51:56,170 - allrank.utils.ltr_logging - INFO - test DS shape: [1133, 100, 136]
2023-08-09 18:51:56,171 - allrank.utils.ltr_logging - INFO - Will pad to the longest slate: 100
2023-08-09 18:51:56,171 - allrank.utils.ltr_logging - INFO - total batch size is 20
2023-08-09 18:51:56,171 - allrank.utils.ltr_logging - INFO - Model training will execute on cpu
2023-08-09 18:51:56,178 - allrank.utils.ltr_logging - INFO - Model has 168297 trainable parameters
2023-08-09 18:51:56,179 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 19:00:49,637 - allrank.utils.ltr_logging - INFO - Epoch : 0 Train loss: 0.15741324206595067 Val loss: 0.151577390730381 Train ndcg_5 0.1803773194551468 Train ndcg_10 0.2098483294248581 Train lndcg_5 0.25763052701950073 Train lndcg_10 0.28220081329345703 Train lndcg1_5 0.25812557339668274 Train lndcg1_10 0.2824411392211914 Train ndcg1_5 0.1808759868144989 Train ndcg1_10 0.21057821810245514 Train georisk_10 0.2757259011268616 Val ndcg_5 0.18065990507602692 Val ndcg_10 0.20824846625328064 Val lndcg_5 0.2601303458213806 Val lndcg_10 0.28250616788864136 Val lndcg1_5 0.2619631588459015 Val lndcg1_10 0.2843247056007385 Val ndcg1_5 0.18248283863067627 Val ndcg1_10 0.21006157994270325 Val georisk_10 0.27610570192337036
2023-08-09 19:00:49,638 - allrank.utils.ltr_logging - INFO - Current:0.20824846625328064 Best:0.0
2023-08-09 19:01:03,485 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.17714049886199634, 'ndcg_10': 0.20812090145245263, 'lndcg_5': 0.25620555306521425, 'lndcg_10': 0.2825790913928214, 'lndcg1_5': 0.2570881655983122, 'lndcg1_10': 0.2834617039259194, 'ndcg1_5': 0.1780231113950943, 'ndcg1_10': 0.2090035139855506} 
2023-08-09 19:01:03,485 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 19:09:58,178 - allrank.utils.ltr_logging - INFO - Epoch : 1 Train loss: 0.15282148043846547 Val loss: 0.14864715614489146 Train ndcg_5 0.18361489474773407 Train ndcg_10 0.21280331909656525 Train lndcg_5 0.2609858512878418 Train lndcg_10 0.28461456298828125 Train lndcg1_5 0.26134464144706726 Train lndcg1_10 0.285419762134552 Train ndcg1_5 0.18368443846702576 Train ndcg1_10 0.21310333907604218 Train georisk_10 0.27722710371017456 Val ndcg_5 0.18373186886310577 Val ndcg_10 0.21112971007823944 Val lndcg_5 0.2634851634502411 Val lndcg_10 0.28540876507759094 Val lndcg1_5 0.2652708888053894 Val lndcg1_10 0.2871944308280945 Val ndcg1_5 0.18551157414913177 Val ndcg1_10 0.21291103959083557 Val georisk_10 0.2770077586174011
2023-08-09 19:09:58,180 - allrank.utils.ltr_logging - INFO - Current:0.21112971007823944 Best:0.20824846625328064
2023-08-09 19:10:11,607 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.1826611454941673, 'ndcg_10': 0.21282947447206982, 'lndcg_5': 0.2627101139874977, 'lndcg_10': 0.28768031394327526, 'lndcg1_5': 0.2635927265205957, 'lndcg1_10': 0.2885629264763732, 'ndcg1_5': 0.18354375802726527, 'ndcg1_10': 0.21371208700516778} 
2023-08-09 19:10:11,607 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 19:19:05,611 - allrank.utils.ltr_logging - INFO - Epoch : 2 Train loss: 0.1510345890197072 Val loss: 0.14730954595974513 Train ndcg_5 0.18687324225902557 Train ndcg_10 0.2161571979522705 Train lndcg_5 0.2646886110305786 Train lndcg_10 0.28833630681037903 Train lndcg1_5 0.2646956443786621 Train lndcg1_10 0.2886662483215332 Train ndcg1_5 0.18751473724842072 Train ndcg1_10 0.21702203154563904 Train georisk_10 0.27922412753105164 Val ndcg_5 0.1879667341709137 Val ndcg_10 0.2144773006439209 Val lndcg_5 0.267532080411911 Val lndcg_10 0.2888493537902832 Val lndcg1_5 0.2693079113960266 Val lndcg1_10 0.2906281352043152 Val ndcg1_5 0.18975773453712463 Val ndcg1_10 0.21626703441143036 Val georisk_10 0.2793331742286682
2023-08-09 19:19:05,614 - allrank.utils.ltr_logging - INFO - Current:0.2144773006439209 Best:0.21112971007823944
2023-08-09 19:19:19,098 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.18652746593546005, 'ndcg_10': 0.21488993058160633, 'lndcg_5': 0.2656422976005876, 'lndcg_10': 0.28925992408488604, 'lndcg1_5': 0.26652491013368557, 'lndcg1_10': 0.290142536617984, 'ndcg1_5': 0.18741007846855803, 'ndcg1_10': 0.21577254311470428} 
2023-08-09 19:19:19,098 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 19:28:13,067 - allrank.utils.ltr_logging - INFO - Epoch : 3 Train loss: 0.14985607770289902 Val loss: 0.1466416854943548 Train ndcg_5 0.19070301949977875 Train ndcg_10 0.21962398290634155 Train lndcg_5 0.2686794102191925 Train lndcg_10 0.2920822501182556 Train lndcg1_5 0.27022749185562134 Train lndcg1_10 0.2933119833469391 Train ndcg1_5 0.19037216901779175 Train ndcg1_10 0.21985825896263123 Train georisk_10 0.2812785804271698 Val ndcg_5 0.18999290466308594 Val ndcg_10 0.2184959501028061 Val lndcg_5 0.27057695388793945 Val lndcg_10 0.29259952902793884 Val lndcg1_5 0.27231982350349426 Val lndcg1_10 0.29437634348869324 Val ndcg1_5 0.1917528361082077 Val ndcg1_10 0.22027628123760223 Val georisk_10 0.28183016180992126
2023-08-09 19:28:13,070 - allrank.utils.ltr_logging - INFO - Current:0.2184959501028061 Best:0.2144773006439209
2023-08-09 19:28:26,354 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.18755962727021638, 'ndcg_10': 0.21857252091713722, 'lndcg_5': 0.26734815709854076, 'lndcg_10': 0.2932783798920375, 'lndcg1_5': 0.2682307696316387, 'lndcg1_10': 0.29416099242513544, 'ndcg1_5': 0.18844223980331434, 'ndcg1_10': 0.21945513345023518} 
2023-08-09 19:28:26,354 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 19:37:20,718 - allrank.utils.ltr_logging - INFO - Epoch : 4 Train loss: 0.14944162316316895 Val loss: 0.146288985652583 Train ndcg_5 0.19401168823242188 Train ndcg_10 0.22339200973510742 Train lndcg_5 0.273481160402298 Train lndcg_10 0.2961914539337158 Train lndcg1_5 0.27372634410858154 Train lndcg1_10 0.29639407992362976 Train ndcg1_5 0.1943637728691101 Train ndcg1_10 0.2239389270544052 Train georisk_10 0.2830926179885864 Val ndcg_5 0.19291162490844727 Val ndcg_10 0.22123411297798157 Val lndcg_5 0.2744239568710327 Val lndcg_10 0.2954399883747101 Val lndcg1_5 0.27620968222618103 Val lndcg1_10 0.29722729325294495 Val ndcg1_5 0.1946973353624344 Val ndcg1_10 0.22301839292049408 Val georisk_10 0.2837432026863098
2023-08-09 19:37:20,720 - allrank.utils.ltr_logging - INFO - Current:0.22123411297798157 Best:0.2184959501028061
2023-08-09 19:37:34,018 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.19272795541043497, 'ndcg_10': 0.22103940892381282, 'lndcg_5': 0.27329107148466625, 'lndcg_10': 0.29573959608461026, 'lndcg1_5': 0.2741736840177642, 'lndcg1_10': 0.2966222086177082, 'ndcg1_5': 0.19361056794353296, 'ndcg1_10': 0.2219220214569108} 
2023-08-09 19:37:34,019 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 19:46:28,252 - allrank.utils.ltr_logging - INFO - Epoch : 5 Train loss: 0.1495911358802348 Val loss: 0.1460796030504363 Train ndcg_5 0.1986098438501358 Train ndcg_10 0.22707924246788025 Train lndcg_5 0.2788863182067871 Train lndcg_10 0.30091243982315063 Train lndcg1_5 0.2786289155483246 Train lndcg1_10 0.3011082112789154 Train ndcg1_5 0.19854246079921722 Train ndcg1_10 0.22752515971660614 Train georisk_10 0.2857716381549835 Val ndcg_5 0.19957487285137177 Val ndcg_10 0.22624462842941284 Val lndcg_5 0.28067198395729065 Val lndcg_10 0.30041709542274475 Val lndcg1_5 0.28252366185188293 Val lndcg1_10 0.30220675468444824 Val ndcg1_5 0.2013351172208786 Val ndcg1_10 0.22803230583667755 Val georisk_10 0.2868437170982361
2023-08-09 19:46:28,253 - allrank.utils.ltr_logging - INFO - Current:0.22624462842941284 Best:0.22123411297798157
2023-08-09 19:46:41,703 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.199384008898972, 'ndcg_10': 0.2260195110729505, 'lndcg_5': 0.2816909000209087, 'lndcg_10': 0.301536635819092, 'lndcg1_5': 0.2825735125540067, 'lndcg1_10': 0.30241924835219, 'ndcg1_5': 0.20026662143206997, 'ndcg1_10': 0.2269021236060485} 
2023-08-09 19:46:41,703 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 19:55:35,683 - allrank.utils.ltr_logging - INFO - Epoch : 6 Train loss: 0.14924548446232352 Val loss: 0.1459466548902648 Train ndcg_5 0.2005481868982315 Train ndcg_10 0.2291451096534729 Train lndcg_5 0.2817934453487396 Train lndcg_10 0.3034958243370056 Train lndcg1_5 0.2812959849834442 Train lndcg1_10 0.30328479409217834 Train ndcg1_5 0.20160287618637085 Train ndcg1_10 0.2300792932510376 Train georisk_10 0.28633058071136475 Val ndcg_5 0.20266546308994293 Val ndcg_10 0.2305917739868164 Val lndcg_5 0.2835943102836609 Val lndcg_10 0.30501654744148254 Val lndcg1_5 0.2853800058364868 Val lndcg1_10 0.30680227279663086 Val ndcg1_5 0.20445117354393005 Val ndcg1_10 0.23237869143486023 Val georisk_10 0.28906750679016113
2023-08-09 19:55:35,686 - allrank.utils.ltr_logging - INFO - Current:0.2305917739868164 Best:0.22624462842941284
2023-08-09 19:55:50,006 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.2015749479194702, 'ndcg_10': 0.2290718980069217, 'lndcg_5': 0.28466724354165035, 'lndcg_10': 0.304721405802911, 'lndcg1_5': 0.2855498560747483, 'lndcg1_10': 0.305604018336009, 'ndcg1_5': 0.20245756045256816, 'ndcg1_10': 0.22995451054001967} 
2023-08-09 19:55:50,007 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 20:04:44,276 - allrank.utils.ltr_logging - INFO - Epoch : 7 Train loss: 0.1491516116625629 Val loss: 0.14585074569497788 Train ndcg_5 0.2033366709947586 Train ndcg_10 0.23201850056648254 Train lndcg_5 0.28324800729751587 Train lndcg_10 0.3052854537963867 Train lndcg1_5 0.28428491950035095 Train lndcg1_10 0.3058980405330658 Train ndcg1_5 0.20425103604793549 Train ndcg1_10 0.23321767151355743 Train georisk_10 0.2883612811565399 Val ndcg_5 0.20541580021381378 Val ndcg_10 0.23250997066497803 Val lndcg_5 0.2870190441608429 Val lndcg_10 0.30725282430648804 Val lndcg1_5 0.2887949049472809 Val lndcg1_10 0.3090303838253021 Val ndcg1_5 0.2072015106678009 Val ndcg1_10 0.23429685831069946 Val georisk_10 0.2901251018047333
2023-08-09 20:04:44,279 - allrank.utils.ltr_logging - INFO - Current:0.23250997066497803 Best:0.2305917739868164
2023-08-09 20:04:58,489 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.20563410050110104, 'ndcg_10': 0.23236562362134255, 'lndcg_5': 0.2893632187172716, 'lndcg_10': 0.3088955685616815, 'lndcg1_5': 0.2902458312503696, 'lndcg1_10': 0.30977818109477945, 'ndcg1_5': 0.206516713034199, 'ndcg1_10': 0.2332482361544405} 
2023-08-09 20:04:58,490 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 20:13:52,255 - allrank.utils.ltr_logging - INFO - Epoch : 8 Train loss: 0.14912382397207566 Val loss: 0.1457747859614236 Train ndcg_5 0.20719894766807556 Train ndcg_10 0.23502996563911438 Train lndcg_5 0.2894561290740967 Train lndcg_10 0.30988627672195435 Train lndcg1_5 0.29102736711502075 Train lndcg1_10 0.31119486689567566 Train ndcg1_5 0.2068263292312622 Train ndcg1_10 0.23552988469600677 Train georisk_10 0.290646493434906 Val ndcg_5 0.20994289219379425 Val ndcg_10 0.2365460842847824 Val lndcg_5 0.2924984097480774 Val lndcg_10 0.3117590546607971 Val lndcg1_5 0.29428407549858093 Val lndcg1_10 0.31354352831840515 Val ndcg1_5 0.21172331273555756 Val ndcg1_10 0.23832890391349792 Val georisk_10 0.2930477559566498
2023-08-09 20:13:52,256 - allrank.utils.ltr_logging - INFO - Current:0.2365460842847824 Best:0.23250997066497803
2023-08-09 20:14:05,771 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.2085601773369951, 'ndcg_10': 0.2362599425316069, 'lndcg_5': 0.293113075864466, 'lndcg_10': 0.3132006676456415, 'lndcg1_5': 0.29399568839756396, 'lndcg1_10': 0.3140832801787395, 'ndcg1_5': 0.20944278987009307, 'ndcg1_10': 0.23714255506470486} 
2023-08-09 20:14:05,771 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 20:22:59,328 - allrank.utils.ltr_logging - INFO - Epoch : 9 Train loss: 0.1490194872891723 Val loss: 0.1457113538469587 Train ndcg_5 0.210081085562706 Train ndcg_10 0.23808415234088898 Train lndcg_5 0.29293185472488403 Train lndcg_10 0.3130366802215576 Train lndcg1_5 0.2940789461135864 Train lndcg1_10 0.3143782615661621 Train ndcg1_5 0.20900285243988037 Train ndcg1_10 0.23796646296977997 Train georisk_10 0.2921350598335266 Val ndcg_5 0.2151017040014267 Val ndcg_10 0.2406185418367386 Val lndcg_5 0.2978878319263458 Val lndcg_10 0.31606146693229675 Val lndcg1_5 0.29967355728149414 Val lndcg1_10 0.31784719228744507 Val ndcg1_5 0.2168821394443512 Val ndcg1_10 0.24240022897720337 Val georisk_10 0.29570212960243225
2023-08-09 20:22:59,329 - allrank.utils.ltr_logging - INFO - Current:0.2406185418367386 Best:0.2365460842847824
2023-08-09 20:23:13,426 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.21156400307303533, 'ndcg_10': 0.2396902538568455, 'lndcg_5': 0.2971710977102414, 'lndcg_10': 0.317530875425752, 'lndcg1_5': 0.2980537102433394, 'lndcg1_10': 0.31841348795884994, 'ndcg1_5': 0.2124466156061333, 'ndcg1_10': 0.2405728663899435} 
2023-08-09 20:23:13,426 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 20:32:06,975 - allrank.utils.ltr_logging - INFO - Epoch : 10 Train loss: 0.14893742357689715 Val loss: 0.14565127449376242 Train ndcg_5 0.21352218091487885 Train ndcg_10 0.24183343350887299 Train lndcg_5 0.2965869903564453 Train lndcg_10 0.31664833426475525 Train lndcg1_5 0.2958984375 Train lndcg1_10 0.31656506657600403 Train ndcg1_5 0.21329714357852936 Train ndcg1_10 0.2417858988046646 Train georisk_10 0.2946131229400635 Val ndcg_5 0.21619440615177155 Val ndcg_10 0.24314959347248077 Val lndcg_5 0.2994014024734497 Val lndcg_10 0.31892040371894836 Val lndcg1_5 0.30114805698394775 Val lndcg1_10 0.32070252299308777 Val ndcg1_5 0.21798013150691986 Val ndcg1_10 0.2449345737695694 Val georisk_10 0.2973289489746094
2023-08-09 20:32:06,977 - allrank.utils.ltr_logging - INFO - Current:0.24314959347248077 Best:0.2406185418367386
2023-08-09 20:32:20,466 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.21585879131059385, 'ndcg_10': 0.24408638353029644, 'lndcg_5': 0.30234058224086563, 'lndcg_10': 0.3222912642833148, 'lndcg1_5': 0.3032231947739636, 'lndcg1_10': 0.32317387681641274, 'ndcg1_5': 0.2167414038436918, 'ndcg1_10': 0.2449689960633944} 
2023-08-09 20:32:20,466 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 20:41:15,020 - allrank.utils.ltr_logging - INFO - Epoch : 11 Train loss: 0.14861543679875683 Val loss: 0.14559505986315863 Train ndcg_5 0.21599917113780975 Train ndcg_10 0.244633749127388 Train lndcg_5 0.300324946641922 Train lndcg_10 0.3206620514392853 Train lndcg1_5 0.30094197392463684 Train lndcg1_10 0.3220939040184021 Train ndcg1_5 0.21595054864883423 Train ndcg1_10 0.24571213126182556 Train georisk_10 0.2965407967567444 Val ndcg_5 0.21760201454162598 Val ndcg_10 0.2451227754354477 Val lndcg_5 0.30193692445755005 Val lndcg_10 0.32129165530204773 Val lndcg1_5 0.3037225604057312 Val lndcg1_10 0.32307735085487366 Val ndcg1_5 0.21939682960510254 Val ndcg1_10 0.24691526591777802 Val georisk_10 0.2982219159603119
2023-08-09 20:41:15,023 - allrank.utils.ltr_logging - INFO - Current:0.2451227754354477 Best:0.24314959347248077
2023-08-09 20:41:28,630 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.2175748670222056, 'ndcg_10': 0.24816869497042368, 'lndcg_5': 0.3041314102941353, 'lndcg_10': 0.32663466618981685, 'lndcg1_5': 0.3050140228272333, 'lndcg1_10': 0.3275172787229148, 'ndcg1_5': 0.21845747955530356, 'ndcg1_10': 0.24905130750352164} 
2023-08-09 20:41:28,630 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 20:50:22,738 - allrank.utils.ltr_logging - INFO - Epoch : 12 Train loss: 0.1488072040056578 Val loss: 0.1455292765583311 Train ndcg_5 0.21928440034389496 Train ndcg_10 0.2478817254304886 Train lndcg_5 0.30416685342788696 Train lndcg_10 0.3242306411266327 Train lndcg1_5 0.30515289306640625 Train lndcg1_10 0.32565784454345703 Train ndcg1_5 0.22025640308856964 Train ndcg1_10 0.24931439757347107 Train georisk_10 0.2993864417076111 Val ndcg_5 0.22134459018707275 Val ndcg_10 0.2490321546792984 Val lndcg_5 0.3058192729949951 Val lndcg_10 0.32543182373046875 Val lndcg1_5 0.3076440095901489 Val lndcg1_10 0.32721972465515137 Val ndcg1_5 0.22312502562999725 Val ndcg1_10 0.25081488490104675 Val georisk_10 0.3010731637477875
2023-08-09 20:50:22,739 - allrank.utils.ltr_logging - INFO - Current:0.2490321546792984 Best:0.2451227754354477
2023-08-09 20:50:36,847 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.22065290082020245, 'ndcg_10': 0.2511578365353106, 'lndcg_5': 0.3079716866831746, 'lndcg_10': 0.33071376650501766, 'lndcg1_5': 0.30885429921627255, 'lndcg1_10': 0.3315963790381156, 'ndcg1_5': 0.2215355133533004, 'ndcg1_10': 0.2520404490684086} 
2023-08-09 20:50:36,847 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 20:59:31,432 - allrank.utils.ltr_logging - INFO - Epoch : 13 Train loss: 0.14860320429080778 Val loss: 0.14545366487332753 Train ndcg_5 0.22458182275295258 Train ndcg_10 0.2532716393470764 Train lndcg_5 0.3106648325920105 Train lndcg_10 0.33052679896354675 Train lndcg1_5 0.30958831310272217 Train lndcg1_10 0.3303385376930237 Train ndcg1_5 0.2239832878112793 Train ndcg1_10 0.25363296270370483 Train georisk_10 0.30290982127189636 Val ndcg_5 0.2259020060300827 Val ndcg_10 0.2540302574634552 Val lndcg_5 0.3103361427783966 Val lndcg_10 0.33049771189689636 Val lndcg1_5 0.31205976009368896 Val lndcg1_10 0.3322862386703491 Val ndcg1_5 0.22769539058208466 Val ndcg1_10 0.2558125853538513 Val georisk_10 0.3042764961719513
2023-08-09 20:59:31,438 - allrank.utils.ltr_logging - INFO - Current:0.2540302574634552 Best:0.2490321546792984
2023-08-09 20:59:44,896 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.22433836420220418, 'ndcg_10': 0.2563593211947692, 'lndcg_5': 0.3130695955711299, 'lndcg_10': 0.3364569123849945, 'lndcg1_5': 0.31395220810422786, 'lndcg1_10': 0.33733952491809244, 'ndcg1_5': 0.22522097673530214, 'ndcg1_10': 0.25724193372786713} 
2023-08-09 20:59:44,896 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 21:08:40,918 - allrank.utils.ltr_logging - INFO - Epoch : 14 Train loss: 0.14863282397105054 Val loss: 0.14538379439285823 Train ndcg_5 0.22748826444149017 Train ndcg_10 0.25844961404800415 Train lndcg_5 0.3136177957057953 Train lndcg_10 0.3354751765727997 Train lndcg1_5 0.31411927938461304 Train lndcg1_10 0.33610838651657104 Train ndcg1_5 0.2284029871225357 Train ndcg1_10 0.25852641463279724 Train georisk_10 0.30642959475517273 Val ndcg_5 0.22749057412147522 Val ndcg_10 0.257291316986084 Val lndcg_5 0.3124801814556122 Val lndcg_10 0.333997905254364 Val lndcg1_5 0.31432077288627625 Val lndcg1_10 0.33579710125923157 Val ndcg1_5 0.2293134182691574 Val ndcg1_10 0.2590821385383606 Val georisk_10 0.30678585171699524
2023-08-09 21:08:40,918 - allrank.utils.ltr_logging - INFO - Current:0.257291316986084 Best:0.2540302574634552
2023-08-09 21:08:54,267 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.22878989472914882, 'ndcg_10': 0.26090931163656356, 'lndcg_5': 0.31825904137160616, 'lndcg_10': 0.3412235037054375, 'lndcg1_5': 0.31914165390470417, 'lndcg1_10': 0.3421061162385355, 'ndcg1_5': 0.22967250726224678, 'ndcg1_10': 0.2617919241696615} 
2023-08-09 21:08:54,268 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 21:17:48,879 - allrank.utils.ltr_logging - INFO - Epoch : 15 Train loss: 0.14857121820770347 Val loss: 0.14528390233005797 Train ndcg_5 0.2305959314107895 Train ndcg_10 0.26243191957473755 Train lndcg_5 0.3174084722995758 Train lndcg_10 0.33891037106513977 Train lndcg1_5 0.31807494163513184 Train lndcg1_10 0.3403007388114929 Train ndcg1_5 0.23159264028072357 Train ndcg1_10 0.26226189732551575 Train georisk_10 0.30884507298469543 Val ndcg_5 0.2319621443748474 Val ndcg_10 0.2602403461933136 Val lndcg_5 0.31680354475975037 Val lndcg_10 0.336892694234848 Val lndcg1_5 0.31862834095954895 Val lndcg1_10 0.33867913484573364 Val ndcg1_5 0.23374298214912415 Val ndcg1_10 0.2620019018650055 Val georisk_10 0.3089567720890045
2023-08-09 21:17:48,881 - allrank.utils.ltr_logging - INFO - Current:0.2602403461933136 Best:0.257291316986084
2023-08-09 21:18:02,373 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.23222104937099766, 'ndcg_10': 0.265165342950346, 'lndcg_5': 0.32179065479776825, 'lndcg_10': 0.34582133328588877, 'lndcg1_5': 0.32267326733086626, 'lndcg1_10': 0.3467039458189867, 'ndcg1_5': 0.23310366190409565, 'ndcg1_10': 0.26604795548344395} 
2023-08-09 21:18:02,373 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 21:26:56,839 - allrank.utils.ltr_logging - INFO - Epoch : 16 Train loss: 0.14839353682953418 Val loss: 0.14520017483404704 Train ndcg_5 0.2331545054912567 Train ndcg_10 0.26619499921798706 Train lndcg_5 0.31994181871414185 Train lndcg_10 0.34342673420906067 Train lndcg1_5 0.3193753659725189 Train lndcg1_10 0.3441668748855591 Train ndcg1_5 0.2358546406030655 Train ndcg1_10 0.26745787262916565 Train georisk_10 0.31316131353378296 Val ndcg_5 0.23499369621276855 Val ndcg_10 0.26423564553260803 Val lndcg_5 0.3197273313999176 Val lndcg_10 0.3410244584083557 Val lndcg1_5 0.32152268290519714 Val lndcg1_10 0.34281685948371887 Val ndcg1_5 0.23685915768146515 Val ndcg1_10 0.2660795748233795 Val georisk_10 0.31072941422462463
2023-08-09 21:26:56,841 - allrank.utils.ltr_logging - INFO - Current:0.26423564553260803 Best:0.2602403461933136
2023-08-09 21:27:10,473 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.23444061872771832, 'ndcg_10': 0.26677860592928837, 'lndcg_5': 0.3238841116640584, 'lndcg_10': 0.34712758074301486, 'lndcg1_5': 0.32476672419715635, 'lndcg1_10': 0.3480101932761128, 'ndcg1_5': 0.23532323126081628, 'ndcg1_10': 0.26766121846238633} 
2023-08-09 21:27:10,474 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 21:36:06,432 - allrank.utils.ltr_logging - INFO - Epoch : 17 Train loss: 0.148171443081554 Val loss: 0.1450957911355155 Train ndcg_5 0.23674376308918 Train ndcg_10 0.26844921708106995 Train lndcg_5 0.32220181822776794 Train lndcg_10 0.3448246717453003 Train lndcg1_5 0.32417652010917664 Train lndcg1_10 0.34674423933029175 Train ndcg1_5 0.23832806944847107 Train ndcg1_10 0.2689571678638458 Train georisk_10 0.3134208917617798 Val ndcg_5 0.2372979074716568 Val ndcg_10 0.26626336574554443 Val lndcg_5 0.3219684064388275 Val lndcg_10 0.3430508077144623 Val lndcg1_5 0.3237605094909668 Val lndcg1_10 0.34482213854789734 Val ndcg1_5 0.2390773743391037 Val ndcg1_10 0.2680336534976959 Val georisk_10 0.3116796612739563
2023-08-09 21:36:06,435 - allrank.utils.ltr_logging - INFO - Current:0.26626336574554443 Best:0.26423564553260803
2023-08-09 21:36:19,958 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.23813777135303865, 'ndcg_10': 0.2683269326146388, 'lndcg_5': 0.3277332441341567, 'lndcg_10': 0.3488559494680154, 'lndcg1_5': 0.3286158566672547, 'lndcg1_10': 0.34973856200111336, 'ndcg1_5': 0.23902038388613664, 'ndcg1_10': 0.26920954514773676} 
2023-08-09 21:36:19,958 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 21:45:16,836 - allrank.utils.ltr_logging - INFO - Epoch : 18 Train loss: 0.14820842593017042 Val loss: 0.14498873267854964 Train ndcg_5 0.24083995819091797 Train ndcg_10 0.2709167003631592 Train lndcg_5 0.3264995515346527 Train lndcg_10 0.3484647572040558 Train lndcg1_5 0.3276442587375641 Train lndcg1_10 0.3490380048751831 Train ndcg1_5 0.2419590950012207 Train ndcg1_10 0.27114778757095337 Train georisk_10 0.3149412274360657 Val ndcg_5 0.2416556179523468 Val ndcg_10 0.2695743143558502 Val lndcg_5 0.3265478312969208 Val lndcg_10 0.34653440117836 Val lndcg1_5 0.3283335566520691 Val lndcg1_10 0.3483201265335083 Val ndcg1_5 0.24344131350517273 Val ndcg1_10 0.2713596522808075 Val georisk_10 0.3143777549266815
2023-08-09 21:45:16,840 - allrank.utils.ltr_logging - INFO - Current:0.2695743143558502 Best:0.26626336574554443
2023-08-09 21:45:30,461 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.24225969274481923, 'ndcg_10': 0.27001213541927216, 'lndcg_5': 0.3328506965432052, 'lndcg_10': 0.3508686802842462, 'lndcg1_5': 0.3337333090763032, 'lndcg1_10': 0.3517512928173442, 'ndcg1_5': 0.2431423052779172, 'ndcg1_10': 0.2708947479523701} 
2023-08-09 21:45:30,461 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 21:54:24,081 - allrank.utils.ltr_logging - INFO - Epoch : 19 Train loss: 0.14803303145370875 Val loss: 0.14488569859947478 Train ndcg_5 0.24388770759105682 Train ndcg_10 0.27223727107048035 Train lndcg_5 0.3290787637233734 Train lndcg_10 0.3504529893398285 Train lndcg1_5 0.33195698261260986 Train lndcg1_10 0.3517589867115021 Train ndcg1_5 0.2452065348625183 Train ndcg1_10 0.27414387464523315 Train georisk_10 0.31667283177375793 Val ndcg_5 0.24585241079330444 Val ndcg_10 0.27198484539985657 Val lndcg_5 0.3307395875453949 Val lndcg_10 0.3490239977836609 Val lndcg1_5 0.3325342535972595 Val lndcg1_10 0.35081586241722107 Val ndcg1_5 0.24763597548007965 Val ndcg1_10 0.27376821637153625 Val georisk_10 0.3159659802913666
2023-08-09 21:54:24,083 - allrank.utils.ltr_logging - INFO - Current:0.27198484539985657 Best:0.2695743143558502
2023-08-09 21:54:37,538 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.24423487789876955, 'ndcg_10': 0.27247212478861027, 'lndcg_5': 0.33480405623571224, 'lndcg_10': 0.353293704368365, 'lndcg1_5': 0.33568666876881026, 'lndcg1_10': 0.354176316901463, 'ndcg1_5': 0.24511749043186754, 'ndcg1_10': 0.27335473732170823} 
2023-08-09 21:54:37,539 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 22:03:33,876 - allrank.utils.ltr_logging - INFO - Epoch : 20 Train loss: 0.14763603722122245 Val loss: 0.1447795650788716 Train ndcg_5 0.24808891117572784 Train ndcg_10 0.27629169821739197 Train lndcg_5 0.3347747325897217 Train lndcg_10 0.3543897867202759 Train lndcg1_5 0.3349095582962036 Train lndcg1_10 0.35466864705085754 Train ndcg1_5 0.24697014689445496 Train ndcg1_10 0.2761918306350708 Train georisk_10 0.3186778724193573 Val ndcg_5 0.24772962927818298 Val ndcg_10 0.2746586799621582 Val lndcg_5 0.33338144421577454 Val lndcg_10 0.3520796000957489 Val lndcg1_5 0.33516016602516174 Val lndcg1_10 0.35386040806770325 Val ndcg1_5 0.24952135980129242 Val ndcg1_10 0.2764487862586975 Val georisk_10 0.31818345189094543
2023-08-09 22:03:33,879 - allrank.utils.ltr_logging - INFO - Current:0.2746586799621582 Best:0.27198484539985657
2023-08-09 22:03:47,224 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.24628910370192425, 'ndcg_10': 0.2754896491034096, 'lndcg_5': 0.3371486258537967, 'lndcg_10': 0.3569175730175104, 'lndcg1_5': 0.33803123838689464, 'lndcg1_10': 0.3578001855506084, 'ndcg1_5': 0.2471717162350222, 'ndcg1_10': 0.2763722616365076} 
2023-08-09 22:03:47,224 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 22:12:42,446 - allrank.utils.ltr_logging - INFO - Epoch : 21 Train loss: 0.14773553905239883 Val loss: 0.14466291133846557 Train ndcg_5 0.25077638030052185 Train ndcg_10 0.27771076560020447 Train lndcg_5 0.3358921408653259 Train lndcg_10 0.35419198870658875 Train lndcg1_5 0.3380849361419678 Train lndcg1_10 0.3555992543697357 Train ndcg1_5 0.2518326938152313 Train ndcg1_10 0.27802273631095886 Train georisk_10 0.31810829043388367 Val ndcg_5 0.25101184844970703 Val ndcg_10 0.2748057246208191 Val lndcg_5 0.3364914357662201 Val lndcg_10 0.35160398483276367 Val lndcg1_5 0.33826717734336853 Val lndcg1_10 0.353381484746933 Val ndcg1_5 0.25274622440338135 Val ndcg1_10 0.27655479311943054 Val georisk_10 0.31797361373901367
2023-08-09 22:12:42,447 - allrank.utils.ltr_logging - INFO - Current:0.2748057246208191 Best:0.2746586799621582
2023-08-09 22:12:56,460 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.25010448907248517, 'ndcg_10': 0.2755910924262737, 'lndcg_5': 0.3411065569088651, 'lndcg_10': 0.35682154977337405, 'lndcg1_5': 0.34198916944196306, 'lndcg1_10': 0.357704162306472, 'ndcg1_5': 0.25098710160558313, 'ndcg1_10': 0.2764737049593717} 
2023-08-09 22:12:56,460 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 22:21:51,066 - allrank.utils.ltr_logging - INFO - Epoch : 22 Train loss: 0.14780991830672338 Val loss: 0.14458471536636353 Train ndcg_5 0.25252565741539 Train ndcg_10 0.2795838415622711 Train lndcg_5 0.3392392694950104 Train lndcg_10 0.3575291037559509 Train lndcg1_5 0.34121426939964294 Train lndcg1_10 0.35859233140945435 Train ndcg1_5 0.2539639472961426 Train ndcg1_10 0.2806905210018158 Train georisk_10 0.320330947637558 Val ndcg_5 0.2508147954940796 Val ndcg_10 0.2773081064224243 Val lndcg_5 0.33660590648651123 Val lndcg_10 0.35394996404647827 Val lndcg1_5 0.33838048577308655 Val lndcg1_10 0.35572734475135803 Val ndcg1_5 0.2525945007801056 Val ndcg1_10 0.27908945083618164 Val georisk_10 0.31940969824790955
2023-08-09 22:21:51,068 - allrank.utils.ltr_logging - INFO - Current:0.2773081064224243 Best:0.2748057246208191
2023-08-09 22:22:05,287 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.2530484013013766, 'ndcg_10': 0.2765636113072961, 'lndcg_5': 0.3441510610136821, 'lndcg_10': 0.35744360561309546, 'lndcg1_5': 0.34503367354678005, 'lndcg1_10': 0.3583262181461934, 'ndcg1_5': 0.25393101383447464, 'ndcg1_10': 0.2774462238403941} 
2023-08-09 22:22:05,287 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 22:30:58,712 - allrank.utils.ltr_logging - INFO - Epoch : 23 Train loss: 0.14737823271099504 Val loss: 0.14447730566774095 Train ndcg_5 0.25633570551872253 Train ndcg_10 0.28198179602622986 Train lndcg_5 0.34230417013168335 Train lndcg_10 0.35941797494888306 Train lndcg1_5 0.3422129452228546 Train lndcg1_10 0.3596406877040863 Train ndcg1_5 0.2569531500339508 Train ndcg1_10 0.28192949295043945 Train georisk_10 0.32134297490119934 Val ndcg_5 0.2544004023075104 Val ndcg_10 0.27932673692703247 Val lndcg_5 0.340310275554657 Val lndcg_10 0.3563039302825928 Val lndcg1_5 0.3420848548412323 Val lndcg1_10 0.35808131098747253 Val ndcg1_5 0.2561347782611847 Val ndcg1_10 0.2810750901699066 Val georisk_10 0.3207319676876068
2023-08-09 22:30:58,713 - allrank.utils.ltr_logging - INFO - Current:0.27932673692703247 Best:0.2773081064224243
2023-08-09 22:31:12,238 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.25596343755427, 'ndcg_10': 0.2792408103745672, 'lndcg_5': 0.34790362466986835, 'lndcg_10': 0.3609075847641556, 'lndcg1_5': 0.3487862372029663, 'lndcg1_10': 0.36179019729725354, 'ndcg1_5': 0.25684605008736794, 'ndcg1_10': 0.2801234229076652} 
2023-08-09 22:31:12,238 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 22:40:06,925 - allrank.utils.ltr_logging - INFO - Epoch : 24 Train loss: 0.14743950541153214 Val loss: 0.14436816104820796 Train ndcg_5 0.2587496340274811 Train ndcg_10 0.2841159701347351 Train lndcg_5 0.3461182117462158 Train lndcg_10 0.36230024695396423 Train lndcg1_5 0.34623315930366516 Train lndcg1_10 0.3633436858654022 Train ndcg1_5 0.25849011540412903 Train ndcg1_10 0.284714013338089 Train georisk_10 0.3221825957298279 Val ndcg_5 0.25746461749076843 Val ndcg_10 0.2831501066684723 Val lndcg_5 0.3441392183303833 Val lndcg_10 0.3609248995780945 Val lndcg1_5 0.3459896743297577 Val lndcg1_10 0.3627548813819885 Val ndcg1_5 0.2592321038246155 Val ndcg1_10 0.28494149446487427 Val georisk_10 0.3228940963745117
2023-08-09 22:40:06,926 - allrank.utils.ltr_logging - INFO - Current:0.2831501066684723 Best:0.27932673692703247
2023-08-09 22:40:20,848 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.2579295314518257, 'ndcg_10': 0.28128394632371345, 'lndcg_5': 0.35034996516255756, 'lndcg_10': 0.36399875605075116, 'lndcg1_5': 0.3512325776956555, 'lndcg1_10': 0.3648813685838491, 'ndcg1_5': 0.2588121439849237, 'ndcg1_10': 0.2821665588568114} 
2023-08-09 22:40:20,848 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 22:49:15,076 - allrank.utils.ltr_logging - INFO - Epoch : 25 Train loss: 0.14728938491298277 Val loss: 0.14430632335799082 Train ndcg_5 0.2592088580131531 Train ndcg_10 0.2855663597583771 Train lndcg_5 0.3476335108280182 Train lndcg_10 0.36349278688430786 Train lndcg1_5 0.34828004240989685 Train lndcg1_10 0.3644748330116272 Train ndcg1_5 0.26086705923080444 Train ndcg1_10 0.2862881124019623 Train georisk_10 0.32279813289642334 Val ndcg_5 0.25701603293418884 Val ndcg_10 0.28313326835632324 Val lndcg_5 0.3431888222694397 Val lndcg_10 0.3607760965824127 Val lndcg1_5 0.3449386656284332 Val lndcg1_10 0.3625374436378479 Val ndcg1_5 0.25885915756225586 Val ndcg1_10 0.28496089577674866 Val georisk_10 0.32281824946403503
2023-08-09 22:49:15,079 - allrank.utils.ltr_logging - INFO - Current:0.28313326835632324 Best:0.2831501066684723
2023-08-09 22:49:29,201 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 22:58:22,077 - allrank.utils.ltr_logging - INFO - Epoch : 26 Train loss: 0.1471144804517213 Val loss: 0.1442308383328574 Train ndcg_5 0.2596428394317627 Train ndcg_10 0.2852488160133362 Train lndcg_5 0.34983423352241516 Train lndcg_10 0.364491730928421 Train lndcg1_5 0.34974753856658936 Train lndcg1_10 0.3648068308830261 Train ndcg1_5 0.26101186871528625 Train ndcg1_10 0.2858140766620636 Train georisk_10 0.3238922655582428 Val ndcg_5 0.2602950632572174 Val ndcg_10 0.2850056290626526 Val lndcg_5 0.3470236361026764 Val lndcg_10 0.3629389703273773 Val lndcg1_5 0.34886059165000916 Val lndcg1_10 0.36476001143455505 Val ndcg1_5 0.2620760500431061 Val ndcg1_10 0.28678765892982483 Val georisk_10 0.32398995757102966
2023-08-09 22:58:22,079 - allrank.utils.ltr_logging - INFO - Current:0.2850056290626526 Best:0.2831501066684723
2023-08-09 22:58:35,794 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.2586797328738992, 'ndcg_10': 0.2828913563031026, 'lndcg_5': 0.3516071497566642, 'lndcg_10': 0.3655082984265814, 'lndcg1_5': 0.35248976228976214, 'lndcg1_10': 0.36639091095967935, 'ndcg1_5': 0.2595623454069972, 'ndcg1_10': 0.28377396883620054} 
2023-08-09 22:58:35,795 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 23:07:29,555 - allrank.utils.ltr_logging - INFO - Epoch : 27 Train loss: 0.1471788533237781 Val loss: 0.14421949961355754 Train ndcg_5 0.26524510979652405 Train ndcg_10 0.29164114594459534 Train lndcg_5 0.3512102961540222 Train lndcg_10 0.36842256784439087 Train lndcg1_5 0.354115754365921 Train lndcg1_10 0.3693145215511322 Train ndcg1_5 0.2652910053730011 Train ndcg1_10 0.29088208079338074 Train georisk_10 0.3271576762199402 Val ndcg_5 0.26077544689178467 Val ndcg_10 0.28628745675086975 Val lndcg_5 0.34761273860931396 Val lndcg_10 0.36473971605300903 Val lndcg1_5 0.3492877781391144 Val lndcg1_10 0.3664516508579254 Val ndcg1_5 0.2625611424446106 Val ndcg1_10 0.28807318210601807 Val georisk_10 0.32485610246658325
2023-08-09 23:07:29,559 - allrank.utils.ltr_logging - INFO - Current:0.28628745675086975 Best:0.2850056290626526
2023-08-09 23:07:43,220 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.26278733555814043, 'ndcg_10': 0.28850483430376633, 'lndcg_5': 0.3554835945972594, 'lndcg_10': 0.3711795611350662, 'lndcg1_5': 0.3563662071303574, 'lndcg1_10': 0.3720621736681642, 'ndcg1_5': 0.2636699480912384, 'ndcg1_10': 0.2893874468368643} 
2023-08-09 23:07:43,221 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 23:16:37,262 - allrank.utils.ltr_logging - INFO - Epoch : 28 Train loss: 0.14738853612335887 Val loss: 0.1441410215837615 Train ndcg_5 0.26419761776924133 Train ndcg_10 0.2912597954273224 Train lndcg_5 0.3528341054916382 Train lndcg_10 0.3697790205478668 Train lndcg1_5 0.3533443212509155 Train lndcg1_10 0.3709622621536255 Train ndcg1_5 0.26600927114486694 Train ndcg1_10 0.29324907064437866 Train georisk_10 0.32716602087020874 Val ndcg_5 0.2628079056739807 Val ndcg_10 0.289593905210495 Val lndcg_5 0.3493627905845642 Val lndcg_10 0.36871573328971863 Val lndcg1_5 0.3511527180671692 Val lndcg1_10 0.37050291895866394 Val ndcg1_5 0.2646085023880005 Val ndcg1_10 0.2913707196712494 Val georisk_10 0.3269800543785095
2023-08-09 23:16:37,263 - allrank.utils.ltr_logging - INFO - Current:0.289593905210495 Best:0.28628745675086975
2023-08-09 23:16:50,774 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.26614423484226113, 'ndcg_10': 0.29191523843370565, 'lndcg_5': 0.3594996225963391, 'lndcg_10': 0.37486792331743246, 'lndcg1_5': 0.36038223512943707, 'lndcg1_10': 0.3757505358505305, 'ndcg1_5': 0.2670268473753591, 'ndcg1_10': 0.2927978509668036} 
2023-08-09 23:16:50,774 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 23:25:44,978 - allrank.utils.ltr_logging - INFO - Epoch : 29 Train loss: 0.14713287136215866 Val loss: 0.14411002503974096 Train ndcg_5 0.26383882761001587 Train ndcg_10 0.28905102610588074 Train lndcg_5 0.35119882225990295 Train lndcg_10 0.3675234317779541 Train lndcg1_5 0.353417307138443 Train lndcg1_10 0.3693634569644928 Train ndcg1_5 0.2641746401786804 Train ndcg1_10 0.29018205404281616 Train georisk_10 0.3264624774456024 Val ndcg_5 0.2663818597793579 Val ndcg_10 0.29046234488487244 Val lndcg_5 0.35340163111686707 Val lndcg_10 0.36908870935440063 Val lndcg1_5 0.3551872968673706 Val lndcg1_10 0.3708460032939911 Val ndcg1_5 0.26816755533218384 Val ndcg1_10 0.29226696491241455 Val georisk_10 0.3267352879047394
2023-08-09 23:25:44,981 - allrank.utils.ltr_logging - INFO - Current:0.29046234488487244 Best:0.289593905210495
2023-08-09 23:25:58,540 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.2641337726621282, 'ndcg_10': 0.2896579221433788, 'lndcg_5': 0.35677671712841874, 'lndcg_10': 0.3725504739394975, 'lndcg1_5': 0.3576593296615167, 'lndcg1_10': 0.37343308647259543, 'ndcg1_5': 0.26501638519522613, 'ndcg1_10': 0.2905405346764768} 
2023-08-09 23:25:58,540 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 23:34:52,932 - allrank.utils.ltr_logging - INFO - Epoch : 30 Train loss: 0.1473334124797228 Val loss: 0.14404477391924178 Train ndcg_5 0.26448145508766174 Train ndcg_10 0.2922399044036865 Train lndcg_5 0.35052961111068726 Train lndcg_10 0.3679293990135193 Train lndcg1_5 0.35281163454055786 Train lndcg1_10 0.37069350481033325 Train ndcg1_5 0.2633887231349945 Train ndcg1_10 0.29021555185317993 Train georisk_10 0.32733190059661865 Val ndcg_5 0.26634106040000916 Val ndcg_10 0.29055875539779663 Val lndcg_5 0.3535052239894867 Val lndcg_10 0.3698180913925171 Val lndcg1_5 0.3552968204021454 Val lndcg1_10 0.37157851457595825 Val ndcg1_5 0.26812678575515747 Val ndcg1_10 0.2923455536365509 Val georisk_10 0.326713889837265
2023-08-09 23:34:52,933 - allrank.utils.ltr_logging - INFO - Current:0.29055875539779663 Best:0.29046234488487244
2023-08-09 23:35:06,725 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.26355682930994995, 'ndcg_10': 0.289953684900699, 'lndcg_5': 0.35601500069255165, 'lndcg_10': 0.3731939956738322, 'lndcg1_5': 0.3568976132256496, 'lndcg1_10': 0.3740766082069302, 'ndcg1_5': 0.2644394418430479, 'ndcg1_10': 0.29083629743379696} 
2023-08-09 23:35:06,725 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 23:43:59,949 - allrank.utils.ltr_logging - INFO - Epoch : 31 Train loss: 0.14692722892903834 Val loss: 0.14401095466954367 Train ndcg_5 0.26305148005485535 Train ndcg_10 0.29010143876075745 Train lndcg_5 0.3524926006793976 Train lndcg_10 0.36967119574546814 Train lndcg1_5 0.3530219793319702 Train lndcg1_10 0.3690670132637024 Train ndcg1_5 0.26509255170822144 Train ndcg1_10 0.2907009422779083 Train georisk_10 0.32641273736953735 Val ndcg_5 0.26628342270851135 Val ndcg_10 0.2897930145263672 Val lndcg_5 0.3535424768924713 Val lndcg_10 0.3689332902431488 Val lndcg1_5 0.35534000396728516 Val lndcg1_10 0.3707278370857239 Val ndcg1_5 0.2680691182613373 Val ndcg1_10 0.29157981276512146 Val georisk_10 0.3257617652416229
2023-08-09 23:43:59,950 - allrank.utils.ltr_logging - INFO - Current:0.2897930145263672 Best:0.29055875539779663
2023-08-09 23:44:13,402 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-09 23:53:07,277 - allrank.utils.ltr_logging - INFO - Epoch : 32 Train loss: 0.14699506720597505 Val loss: 0.14399316161870956 Train ndcg_5 0.26706719398498535 Train ndcg_10 0.29334235191345215 Train lndcg_5 0.3526081144809723 Train lndcg_10 0.3710543215274811 Train lndcg1_5 0.35388290882110596 Train lndcg1_10 0.3721708357334137 Train ndcg1_5 0.2660803198814392 Train ndcg1_10 0.29289379715919495 Train georisk_10 0.3281801640987396 Val ndcg_5 0.26431840658187866 Val ndcg_10 0.2898421585559845 Val lndcg_5 0.3516246974468231 Val lndcg_10 0.36972576379776 Val lndcg1_5 0.3534434139728546 Val lndcg1_10 0.3715134561061859 Val ndcg1_5 0.26608359813690186 Val ndcg1_10 0.291626513004303 Val georisk_10 0.32638785243034363
2023-08-09 23:53:07,279 - allrank.utils.ltr_logging - INFO - Current:0.2898421585559845 Best:0.29055875539779663
2023-08-09 23:53:21,415 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 00:02:14,947 - allrank.utils.ltr_logging - INFO - Epoch : 33 Train loss: 0.1468172365275926 Val loss: 0.14394020714930125 Train ndcg_5 0.26662737131118774 Train ndcg_10 0.2929101586341858 Train lndcg_5 0.35432061553001404 Train lndcg_10 0.37154364585876465 Train lndcg1_5 0.3536568284034729 Train lndcg1_10 0.37205904722213745 Train ndcg1_5 0.265461266040802 Train ndcg1_10 0.29344266653060913 Train georisk_10 0.327850341796875 Val ndcg_5 0.2660054862499237 Val ndcg_10 0.29140642285346985 Val lndcg_5 0.35302022099494934 Val lndcg_10 0.3711272180080414 Val lndcg1_5 0.35480591654777527 Val lndcg1_10 0.3729129135608673 Val ndcg1_5 0.2677912414073944 Val ndcg1_10 0.29319077730178833 Val georisk_10 0.3274514079093933
2023-08-10 00:02:14,950 - allrank.utils.ltr_logging - INFO - Current:0.29140642285346985 Best:0.29055875539779663
2023-08-10 00:02:28,505 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.2646835103763993, 'ndcg_10': 0.2915122474034875, 'lndcg_5': 0.3573340835864179, 'lndcg_10': 0.37485585916260566, 'lndcg1_5': 0.3582166961195159, 'lndcg1_10': 0.3757384716957036, 'ndcg1_5': 0.26556612290949727, 'ndcg1_10': 0.29239485993658554} 
2023-08-10 00:02:28,506 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 00:11:24,046 - allrank.utils.ltr_logging - INFO - Epoch : 34 Train loss: 0.14681335303288381 Val loss: 0.14394470942871912 Train ndcg_5 0.2668072283267975 Train ndcg_10 0.2929544150829315 Train lndcg_5 0.3542554974555969 Train lndcg_10 0.3715258836746216 Train lndcg1_5 0.35545167326927185 Train lndcg1_10 0.3728637397289276 Train ndcg1_5 0.26522380113601685 Train ndcg1_10 0.29304322600364685 Train georisk_10 0.3278530538082123 Val ndcg_5 0.2657072842121124 Val ndcg_10 0.29033565521240234 Val lndcg_5 0.3536084294319153 Val lndcg_10 0.3703778386116028 Val lndcg1_5 0.3553941547870636 Val lndcg1_10 0.3721625804901123 Val ndcg1_5 0.2674833834171295 Val ndcg1_10 0.2921144664287567 Val georisk_10 0.3266255557537079
2023-08-10 00:11:24,048 - allrank.utils.ltr_logging - INFO - Current:0.29033565521240234 Best:0.29140642285346985
2023-08-10 00:11:38,336 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 00:20:32,547 - allrank.utils.ltr_logging - INFO - Epoch : 35 Train loss: 0.14681877462791262 Val loss: 0.14392114749976567 Train ndcg_5 0.2660403251647949 Train ndcg_10 0.2932135760784149 Train lndcg_5 0.3549343943595886 Train lndcg_10 0.37159016728401184 Train lndcg1_5 0.3571338653564453 Train lndcg1_10 0.37321770191192627 Train ndcg1_5 0.2656369209289551 Train ndcg1_10 0.29308539628982544 Train georisk_10 0.3274921476840973 Val ndcg_5 0.2657904624938965 Val ndcg_10 0.2899506688117981 Val lndcg_5 0.3540724217891693 Val lndcg_10 0.37036460638046265 Val lndcg1_5 0.35585811734199524 Val lndcg1_10 0.37215152382850647 Val ndcg1_5 0.2675762176513672 Val ndcg1_10 0.2917371690273285 Val georisk_10 0.32684212923049927
2023-08-10 00:20:32,550 - allrank.utils.ltr_logging - INFO - Current:0.2899506688117981 Best:0.29140642285346985
2023-08-10 00:20:45,975 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 00:29:38,221 - allrank.utils.ltr_logging - INFO - Epoch : 36 Train loss: 0.14677220904667537 Val loss: 0.1438548586198262 Train ndcg_5 0.26491662859916687 Train ndcg_10 0.2921491861343384 Train lndcg_5 0.3554036617279053 Train lndcg_10 0.372077614068985 Train lndcg1_5 0.3541482985019684 Train lndcg1_10 0.3719926178455353 Train ndcg1_5 0.26546674966812134 Train ndcg1_10 0.29287612438201904 Train georisk_10 0.32804057002067566 Val ndcg_5 0.266638845205307 Val ndcg_10 0.2910563051700592 Val lndcg_5 0.3554370105266571 Val lndcg_10 0.37173840403556824 Val lndcg1_5 0.35722270607948303 Val lndcg1_10 0.37352412939071655 Val ndcg1_5 0.2684040665626526 Val ndcg1_10 0.29284143447875977 Val georisk_10 0.3271464407444
2023-08-10 00:29:38,225 - allrank.utils.ltr_logging - INFO - Current:0.2910563051700592 Best:0.29140642285346985
2023-08-10 00:29:52,598 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 00:38:46,367 - allrank.utils.ltr_logging - INFO - Epoch : 37 Train loss: 0.1468201581143613 Val loss: 0.14381297252007894 Train ndcg_5 0.26543137431144714 Train ndcg_10 0.29285189509391785 Train lndcg_5 0.35558491945266724 Train lndcg_10 0.3721124231815338 Train lndcg1_5 0.3554992973804474 Train lndcg1_10 0.37359458208084106 Train ndcg1_5 0.26592427492141724 Train ndcg1_10 0.2931194007396698 Train georisk_10 0.3276676833629608 Val ndcg_5 0.26684945821762085 Val ndcg_10 0.29072195291519165 Val lndcg_5 0.35539254546165466 Val lndcg_10 0.37144172191619873 Val lndcg1_5 0.3571782410144806 Val lndcg1_10 0.3732558786869049 Val ndcg1_5 0.26863518357276917 Val ndcg1_10 0.292488694190979 Val georisk_10 0.32689371705055237
2023-08-10 00:38:46,368 - allrank.utils.ltr_logging - INFO - Current:0.29072195291519165 Best:0.29140642285346985
2023-08-10 00:38:59,844 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 00:47:54,380 - allrank.utils.ltr_logging - INFO - Epoch : 38 Train loss: 0.14669305643815322 Val loss: 0.14379462280443736 Train ndcg_5 0.26718488335609436 Train ndcg_10 0.29366764426231384 Train lndcg_5 0.35612669587135315 Train lndcg_10 0.3736952245235443 Train lndcg1_5 0.35720470547676086 Train lndcg1_10 0.3732392191886902 Train ndcg1_5 0.26585501432418823 Train ndcg1_10 0.2931331992149353 Train georisk_10 0.32802116870880127 Val ndcg_5 0.2682700455188751 Val ndcg_10 0.29168346524238586 Val lndcg_5 0.35625946521759033 Val lndcg_10 0.3721490502357483 Val lndcg1_5 0.35804516077041626 Val lndcg1_10 0.3739347755908966 Val ndcg1_5 0.27005574107170105 Val ndcg1_10 0.293450266122818 Val georisk_10 0.3276042938232422
2023-08-10 00:47:54,383 - allrank.utils.ltr_logging - INFO - Current:0.29168346524238586 Best:0.29140642285346985
2023-08-10 00:48:08,062 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.2665245094793701, 'ndcg_10': 0.29243468518388366, 'lndcg_5': 0.3601803804446172, 'lndcg_10': 0.3760724863531891, 'lndcg1_5': 0.36106299297771516, 'lndcg1_10': 0.3769550988862871, 'ndcg1_5': 0.26740712201246813, 'ndcg1_10': 0.2933172977169816} 
2023-08-10 00:48:08,062 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 00:57:02,009 - allrank.utils.ltr_logging - INFO - Epoch : 39 Train loss: 0.14690211142817308 Val loss: 0.14372901086296355 Train ndcg_5 0.2665577828884125 Train ndcg_10 0.2933019697666168 Train lndcg_5 0.3567061126232147 Train lndcg_10 0.3728526830673218 Train lndcg1_5 0.35640403628349304 Train lndcg1_10 0.3736764192581177 Train ndcg1_5 0.267194926738739 Train ndcg1_10 0.2932668626308441 Train georisk_10 0.3275425136089325 Val ndcg_5 0.2679937183856964 Val ndcg_10 0.29206570982933044 Val lndcg_5 0.3563419580459595 Val lndcg_10 0.37237003445625305 Val lndcg1_5 0.3581276834011078 Val lndcg1_10 0.37415575981140137 Val ndcg1_5 0.26979994773864746 Val ndcg1_10 0.2938522398471832 Val georisk_10 0.3270604908466339
2023-08-10 00:57:02,009 - allrank.utils.ltr_logging - INFO - Current:0.29206570982933044 Best:0.29168346524238586
2023-08-10 00:57:15,514 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.26697508933916925, 'ndcg_10': 0.2917509435007642, 'lndcg_5': 0.36120534287200645, 'lndcg_10': 0.3762119313198265, 'lndcg1_5': 0.36208795540510447, 'lndcg1_10': 0.37709454385292446, 'ndcg1_5': 0.2678577018722672, 'ndcg1_10': 0.2926335560338622} 
2023-08-10 00:57:15,514 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 01:06:09,009 - allrank.utils.ltr_logging - INFO - Epoch : 40 Train loss: 0.1466946855751886 Val loss: 0.14373970244612014 Train ndcg_5 0.2667434811592102 Train ndcg_10 0.29336780309677124 Train lndcg_5 0.3580681383609772 Train lndcg_10 0.37513548135757446 Train lndcg1_5 0.3574628531932831 Train lndcg1_10 0.37455302476882935 Train ndcg1_5 0.26679930090904236 Train ndcg1_10 0.2934384346008301 Train georisk_10 0.32929253578186035 Val ndcg_5 0.2678551971912384 Val ndcg_10 0.29134702682495117 Val lndcg_5 0.35648950934410095 Val lndcg_10 0.37181177735328674 Val lndcg1_5 0.35827523469924927 Val lndcg1_10 0.3735691010951996 Val ndcg1_5 0.26964089274406433 Val ndcg1_10 0.2931326925754547 Val georisk_10 0.3268900513648987
2023-08-10 01:06:09,012 - allrank.utils.ltr_logging - INFO - Current:0.29134702682495117 Best:0.29206570982933044
2023-08-10 01:06:22,819 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 01:15:16,175 - allrank.utils.ltr_logging - INFO - Epoch : 41 Train loss: 0.14673448308381354 Val loss: 0.14371333590575627 Train ndcg_5 0.26907533407211304 Train ndcg_10 0.2950584888458252 Train lndcg_5 0.35988497734069824 Train lndcg_10 0.3757686913013458 Train lndcg1_5 0.3587414622306824 Train lndcg1_10 0.3745853900909424 Train ndcg1_5 0.2693796753883362 Train ndcg1_10 0.2948163151741028 Train georisk_10 0.3295665383338928 Val ndcg_5 0.2698640823364258 Val ndcg_10 0.2936803698539734 Val lndcg_5 0.35780617594718933 Val lndcg_10 0.3739367127418518 Val lndcg1_5 0.35959190130233765 Val lndcg1_10 0.37569403648376465 Val ndcg1_5 0.2716497480869293 Val ndcg1_10 0.29546546936035156 Val georisk_10 0.3282565474510193
2023-08-10 01:15:16,176 - allrank.utils.ltr_logging - INFO - Current:0.2936803698539734 Best:0.29206570982933044
2023-08-10 01:15:29,831 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.2685825611488032, 'ndcg_10': 0.2938966561881321, 'lndcg_5': 0.3621198908633738, 'lndcg_10': 0.37806126994321154, 'lndcg1_5': 0.3630025033964718, 'lndcg1_10': 0.3789438824763095, 'ndcg1_5': 0.2694651736819012, 'ndcg1_10': 0.29477926872123006} 
2023-08-10 01:15:29,831 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 01:24:22,568 - allrank.utils.ltr_logging - INFO - Epoch : 42 Train loss: 0.14654839880036616 Val loss: 0.14373774294342315 Train ndcg_5 0.2667354345321655 Train ndcg_10 0.2943281829357147 Train lndcg_5 0.3581581115722656 Train lndcg_10 0.37502506375312805 Train lndcg1_5 0.3588273823261261 Train lndcg1_10 0.3748999238014221 Train ndcg1_5 0.2689269781112671 Train ndcg1_10 0.296154260635376 Train georisk_10 0.32803940773010254 Val ndcg_5 0.26805195212364197 Val ndcg_10 0.2924269139766693 Val lndcg_5 0.3563949763774872 Val lndcg_10 0.37284141778945923 Val lndcg1_5 0.3581477403640747 Val lndcg1_10 0.37462660670280457 Val ndcg1_5 0.26983770728111267 Val ndcg1_10 0.29421350359916687 Val georisk_10 0.32792848348617554
2023-08-10 01:24:22,570 - allrank.utils.ltr_logging - INFO - Current:0.2924269139766693 Best:0.2936803698539734
2023-08-10 01:24:35,825 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 01:33:29,667 - allrank.utils.ltr_logging - INFO - Epoch : 43 Train loss: 0.14660692812540158 Val loss: 0.14366439091307776 Train ndcg_5 0.267940491437912 Train ndcg_10 0.2940865755081177 Train lndcg_5 0.3584751486778259 Train lndcg_10 0.37424129247665405 Train lndcg1_5 0.357653945684433 Train lndcg1_10 0.3739543855190277 Train ndcg1_5 0.2682274281978607 Train ndcg1_10 0.2939460873603821 Train georisk_10 0.32881924510002136 Val ndcg_5 0.26901155710220337 Val ndcg_10 0.2927003800868988 Val lndcg_5 0.3577018082141876 Val lndcg_10 0.37338122725486755 Val lndcg1_5 0.35945457220077515 Val lndcg1_10 0.37519341707229614 Val ndcg1_5 0.2707972228527069 Val ndcg1_10 0.29448607563972473 Val georisk_10 0.32780665159225464
2023-08-10 01:33:29,671 - allrank.utils.ltr_logging - INFO - Current:0.2927003800868988 Best:0.2936803698539734
2023-08-10 01:33:43,262 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 01:42:37,756 - allrank.utils.ltr_logging - INFO - Epoch : 44 Train loss: 0.1467999857788037 Val loss: 0.14363318788153784 Train ndcg_5 0.2688944637775421 Train ndcg_10 0.2954097092151642 Train lndcg_5 0.35878241062164307 Train lndcg_10 0.3755604028701782 Train lndcg1_5 0.3594353497028351 Train lndcg1_10 0.3755306005477905 Train ndcg1_5 0.2692628502845764 Train ndcg1_10 0.2953264117240906 Train georisk_10 0.32863733172416687 Val ndcg_5 0.2704332172870636 Val ndcg_10 0.2939528226852417 Val lndcg_5 0.3589550852775574 Val lndcg_10 0.3749433159828186 Val lndcg1_5 0.3607408106327057 Val lndcg1_10 0.3767278790473938 Val ndcg1_5 0.2722189128398895 Val ndcg1_10 0.29573854804039 Val georisk_10 0.3280963897705078
2023-08-10 01:42:37,758 - allrank.utils.ltr_logging - INFO - Current:0.2939528226852417 Best:0.2936803698539734
2023-08-10 01:42:51,278 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.2674465953772649, 'ndcg_10': 0.2926210007246431, 'lndcg_5': 0.36229790749133894, 'lndcg_10': 0.3780711714115579, 'lndcg1_5': 0.36318052002443696, 'lndcg1_10': 0.3789537839446559, 'ndcg1_5': 0.2683292079103629, 'ndcg1_10': 0.29350361325774105} 
2023-08-10 01:42:51,278 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 01:51:43,569 - allrank.utils.ltr_logging - INFO - Epoch : 45 Train loss: 0.14641507627345396 Val loss: 0.143648267856666 Train ndcg_5 0.2706069052219391 Train ndcg_10 0.2959632873535156 Train lndcg_5 0.3591005504131317 Train lndcg_10 0.37570375204086304 Train lndcg1_5 0.36141276359558105 Train lndcg1_10 0.37728559970855713 Train ndcg1_5 0.2703869044780731 Train ndcg1_10 0.296245813369751 Train georisk_10 0.32850852608680725 Val ndcg_5 0.2701430320739746 Val ndcg_10 0.2942425310611725 Val lndcg_5 0.3587733805179596 Val lndcg_10 0.37477347254753113 Val lndcg1_5 0.3605920374393463 Val lndcg1_10 0.37654227018356323 Val ndcg1_5 0.2719082534313202 Val ndcg1_10 0.2960268259048462 Val georisk_10 0.32886654138565063
2023-08-10 01:51:43,571 - allrank.utils.ltr_logging - INFO - Current:0.2942425310611725 Best:0.2939528226852417
2023-08-10 01:51:57,200 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.2687856449342576, 'ndcg_10': 0.2936526083217704, 'lndcg_5': 0.363923314913196, 'lndcg_10': 0.3792047517099634, 'lndcg1_5': 0.364805927446294, 'lndcg1_10': 0.3800873642430614, 'ndcg1_5': 0.26966825746735557, 'ndcg1_10': 0.2945352208548684} 
2023-08-10 01:51:57,200 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 02:00:50,108 - allrank.utils.ltr_logging - INFO - Epoch : 46 Train loss: 0.1466121478778146 Val loss: 0.14358466118574142 Train ndcg_5 0.2698068618774414 Train ndcg_10 0.2943970561027527 Train lndcg_5 0.360591858625412 Train lndcg_10 0.3755366802215576 Train lndcg1_5 0.3615286946296692 Train lndcg1_10 0.37584933638572693 Train ndcg1_5 0.2700420320034027 Train ndcg1_10 0.29553884267807007 Train georisk_10 0.32940828800201416 Val ndcg_5 0.27056971192359924 Val ndcg_10 0.29520973563194275 Val lndcg_5 0.358956515789032 Val lndcg_10 0.37588047981262207 Val lndcg1_5 0.3607422411441803 Val lndcg1_10 0.3776676058769226 Val ndcg1_5 0.2723759114742279 Val ndcg1_10 0.2969968318939209 Val georisk_10 0.32911014556884766
2023-08-10 02:00:50,110 - allrank.utils.ltr_logging - INFO - Current:0.29520973563194275 Best:0.2942425310611725
2023-08-10 02:01:03,611 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.26747333568635734, 'ndcg_10': 0.2929813197706931, 'lndcg_5': 0.36256260744212826, 'lndcg_10': 0.3787369344371235, 'lndcg1_5': 0.3634452199752262, 'lndcg1_10': 0.37961954697022143, 'ndcg1_5': 0.26835594821945535, 'ndcg1_10': 0.29386393230379104} 
2023-08-10 02:01:03,612 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 02:09:58,560 - allrank.utils.ltr_logging - INFO - Epoch : 47 Train loss: 0.14646942421212492 Val loss: 0.14357080736330577 Train ndcg_5 0.2698196768760681 Train ndcg_10 0.29554808139801025 Train lndcg_5 0.36047327518463135 Train lndcg_10 0.37583452463150024 Train lndcg1_5 0.3610793650150299 Train lndcg1_10 0.3770034909248352 Train ndcg1_5 0.2697432041168213 Train ndcg1_10 0.295550674200058 Train georisk_10 0.3288651406764984 Val ndcg_5 0.27155715227127075 Val ndcg_10 0.29411253333091736 Val lndcg_5 0.36015284061431885 Val lndcg_10 0.37486302852630615 Val lndcg1_5 0.36197152733802795 Val lndcg1_10 0.37664949893951416 Val ndcg1_5 0.27332231402397156 Val ndcg1_10 0.29589763283729553 Val georisk_10 0.32863959670066833
2023-08-10 02:09:58,563 - allrank.utils.ltr_logging - INFO - Current:0.29411253333091736 Best:0.29520973563194275
2023-08-10 02:10:12,196 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 02:19:04,453 - allrank.utils.ltr_logging - INFO - Epoch : 48 Train loss: 0.14640548333793038 Val loss: 0.14352344402245112 Train ndcg_5 0.2687876522541046 Train ndcg_10 0.294506698846817 Train lndcg_5 0.360523521900177 Train lndcg_10 0.3760857582092285 Train lndcg1_5 0.36087512969970703 Train lndcg1_10 0.37535300850868225 Train ndcg1_5 0.2702370882034302 Train ndcg1_10 0.29603883624076843 Train georisk_10 0.3303685188293457 Val ndcg_5 0.27352583408355713 Val ndcg_10 0.29571351408958435 Val lndcg_5 0.361818790435791 Val lndcg_10 0.37614166736602783 Val lndcg1_5 0.36360448598861694 Val lndcg1_10 0.37792736291885376 Val ndcg1_5 0.27531155943870544 Val ndcg1_10 0.2974991798400879 Val georisk_10 0.32920899987220764
2023-08-10 02:19:04,455 - allrank.utils.ltr_logging - INFO - Current:0.29571351408958435 Best:0.29520973563194275
2023-08-10 02:19:17,908 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.2692151545553963, 'ndcg_10': 0.29403060802615233, 'lndcg_5': 0.364261967781882, 'lndcg_10': 0.37933233604723604, 'lndcg1_5': 0.36514458031498, 'lndcg1_10': 0.380214948580334, 'ndcg1_5': 0.2700977670884943, 'ndcg1_10': 0.2949132205592503} 
2023-08-10 02:19:17,908 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 02:28:12,579 - allrank.utils.ltr_logging - INFO - Epoch : 49 Train loss: 0.1464732034750998 Val loss: 0.14357269874640874 Train ndcg_5 0.2725975513458252 Train ndcg_10 0.2970181107521057 Train lndcg_5 0.3636666238307953 Train lndcg_10 0.37759852409362793 Train lndcg1_5 0.3628194034099579 Train lndcg1_10 0.3771548569202423 Train ndcg1_5 0.27313464879989624 Train ndcg1_10 0.29796722531318665 Train georisk_10 0.33005383610725403 Val ndcg_5 0.27310478687286377 Val ndcg_10 0.29523128271102905 Val lndcg_5 0.36175379157066345 Val lndcg_10 0.37599238753318787 Val lndcg1_5 0.36353951692581177 Val lndcg1_10 0.3777766823768616 Val ndcg1_5 0.2748904824256897 Val ndcg1_10 0.2970176935195923 Val georisk_10 0.32931140065193176
2023-08-10 02:28:12,582 - allrank.utils.ltr_logging - INFO - Current:0.29523128271102905 Best:0.29571351408958435
2023-08-10 02:28:26,031 - allrank.utils.ltr_logging - INFO - Ending execution. Train Losses:
[0.15741324206595067, 0.15282148043846547, 0.1510345890197072, 0.14985607770289902, 0.14944162316316895, 0.1495911358802348, 0.14924548446232352, 0.1491516116625629, 0.14912382397207566, 0.1490194872891723, 0.14893742357689715, 0.14861543679875683, 0.1488072040056578, 0.14860320429080778, 0.14863282397105054, 0.14857121820770347, 0.14839353682953418, 0.148171443081554, 0.14820842593017042, 0.14803303145370875, 0.14763603722122245, 0.14773553905239883, 0.14780991830672338, 0.14737823271099504, 0.14743950541153214, 0.14728938491298277, 0.1471144804517213, 0.1471788533237781, 0.14738853612335887, 0.14713287136215866, 0.1473334124797228, 0.14692722892903834, 0.14699506720597505, 0.1468172365275926, 0.14681335303288381, 0.14681877462791262, 0.14677220904667537, 0.1468201581143613, 0.14669305643815322, 0.14690211142817308, 0.1466946855751886, 0.14673448308381354, 0.14654839880036616, 0.14660692812540158, 0.1467999857788037, 0.14641507627345396, 0.1466121478778146, 0.14646942421212492, 0.14640548333793038, 0.1464732034750998]
2023-08-10 02:28:26,031 - allrank.utils.ltr_logging - INFO - Ending execution. Validation Losses (not used to train):
[0.151577390730381, 0.14864715614489146, 0.14730954595974513, 0.1466416854943548, 0.146288985652583, 0.1460796030504363, 0.1459466548902648, 0.14585074569497788, 0.1457747859614236, 0.1457113538469587, 0.14565127449376242, 0.14559505986315863, 0.1455292765583311, 0.14545366487332753, 0.14538379439285823, 0.14528390233005797, 0.14520017483404704, 0.1450957911355155, 0.14498873267854964, 0.14488569859947478, 0.1447795650788716, 0.14466291133846557, 0.14458471536636353, 0.14447730566774095, 0.14436816104820796, 0.14430632335799082, 0.1442308383328574, 0.14421949961355754, 0.1441410215837615, 0.14411002503974096, 0.14404477391924178, 0.14401095466954367, 0.14399316161870956, 0.14394020714930125, 0.14394470942871912, 0.14392114749976567, 0.1438548586198262, 0.14381297252007894, 0.14379462280443736, 0.14372901086296355, 0.14373970244612014, 0.14371333590575627, 0.14373774294342315, 0.14366439091307776, 0.14363318788153784, 0.143648267856666, 0.14358466118574142, 0.14357080736330577, 0.14352344402245112, 0.14357269874640874]
2023-08-10 02:28:26,032 - allrank.utils.ltr_logging - INFO - Ending execution. Train Metrics Evolution:
[{'ndcg_5': 0.18037732, 'ndcg_10': 0.20984833, 'lndcg_5': 0.25763053, 'lndcg_10': 0.2822008, 'lndcg1_5': 0.25812557, 'lndcg1_10': 0.28244114, 'ndcg1_5': 0.18087599, 'ndcg1_10': 0.21057822, 'georisk_10': 0.2757259}, {'ndcg_5': 0.1836149, 'ndcg_10': 0.21280332, 'lndcg_5': 0.26098585, 'lndcg_10': 0.28461456, 'lndcg1_5': 0.26134464, 'lndcg1_10': 0.28541976, 'ndcg1_5': 0.18368444, 'ndcg1_10': 0.21310334, 'georisk_10': 0.2772271}, {'ndcg_5': 0.18687324, 'ndcg_10': 0.2161572, 'lndcg_5': 0.2646886, 'lndcg_10': 0.2883363, 'lndcg1_5': 0.26469564, 'lndcg1_10': 0.28866625, 'ndcg1_5': 0.18751474, 'ndcg1_10': 0.21702203, 'georisk_10': 0.27922413}, {'ndcg_5': 0.19070302, 'ndcg_10': 0.21962398, 'lndcg_5': 0.2686794, 'lndcg_10': 0.29208225, 'lndcg1_5': 0.2702275, 'lndcg1_10': 0.29331198, 'ndcg1_5': 0.19037217, 'ndcg1_10': 0.21985826, 'georisk_10': 0.28127858}, {'ndcg_5': 0.19401169, 'ndcg_10': 0.22339201, 'lndcg_5': 0.27348116, 'lndcg_10': 0.29619145, 'lndcg1_5': 0.27372634, 'lndcg1_10': 0.29639408, 'ndcg1_5': 0.19436377, 'ndcg1_10': 0.22393893, 'georisk_10': 0.28309262}, {'ndcg_5': 0.19860984, 'ndcg_10': 0.22707924, 'lndcg_5': 0.27888632, 'lndcg_10': 0.30091244, 'lndcg1_5': 0.27862892, 'lndcg1_10': 0.3011082, 'ndcg1_5': 0.19854246, 'ndcg1_10': 0.22752516, 'georisk_10': 0.28577164}, {'ndcg_5': 0.20054819, 'ndcg_10': 0.22914511, 'lndcg_5': 0.28179345, 'lndcg_10': 0.30349582, 'lndcg1_5': 0.28129598, 'lndcg1_10': 0.3032848, 'ndcg1_5': 0.20160288, 'ndcg1_10': 0.2300793, 'georisk_10': 0.28633058}, {'ndcg_5': 0.20333667, 'ndcg_10': 0.2320185, 'lndcg_5': 0.283248, 'lndcg_10': 0.30528545, 'lndcg1_5': 0.28428492, 'lndcg1_10': 0.30589804, 'ndcg1_5': 0.20425104, 'ndcg1_10': 0.23321767, 'georisk_10': 0.28836128}, {'ndcg_5': 0.20719895, 'ndcg_10': 0.23502997, 'lndcg_5': 0.28945613, 'lndcg_10': 0.30988628, 'lndcg1_5': 0.29102737, 'lndcg1_10': 0.31119487, 'ndcg1_5': 0.20682633, 'ndcg1_10': 0.23552988, 'georisk_10': 0.2906465}, {'ndcg_5': 0.21008109, 'ndcg_10': 0.23808415, 'lndcg_5': 0.29293185, 'lndcg_10': 0.31303668, 'lndcg1_5': 0.29407895, 'lndcg1_10': 0.31437826, 'ndcg1_5': 0.20900285, 'ndcg1_10': 0.23796646, 'georisk_10': 0.29213506}, {'ndcg_5': 0.21352218, 'ndcg_10': 0.24183343, 'lndcg_5': 0.296587, 'lndcg_10': 0.31664833, 'lndcg1_5': 0.29589844, 'lndcg1_10': 0.31656507, 'ndcg1_5': 0.21329714, 'ndcg1_10': 0.2417859, 'georisk_10': 0.29461312}, {'ndcg_5': 0.21599917, 'ndcg_10': 0.24463375, 'lndcg_5': 0.30032495, 'lndcg_10': 0.32066205, 'lndcg1_5': 0.30094197, 'lndcg1_10': 0.3220939, 'ndcg1_5': 0.21595055, 'ndcg1_10': 0.24571213, 'georisk_10': 0.2965408}, {'ndcg_5': 0.2192844, 'ndcg_10': 0.24788173, 'lndcg_5': 0.30416685, 'lndcg_10': 0.32423064, 'lndcg1_5': 0.3051529, 'lndcg1_10': 0.32565784, 'ndcg1_5': 0.2202564, 'ndcg1_10': 0.2493144, 'georisk_10': 0.29938644}, {'ndcg_5': 0.22458182, 'ndcg_10': 0.25327164, 'lndcg_5': 0.31066483, 'lndcg_10': 0.3305268, 'lndcg1_5': 0.3095883, 'lndcg1_10': 0.33033854, 'ndcg1_5': 0.22398329, 'ndcg1_10': 0.25363296, 'georisk_10': 0.30290982}, {'ndcg_5': 0.22748826, 'ndcg_10': 0.2584496, 'lndcg_5': 0.3136178, 'lndcg_10': 0.33547518, 'lndcg1_5': 0.31411928, 'lndcg1_10': 0.3361084, 'ndcg1_5': 0.22840299, 'ndcg1_10': 0.2585264, 'georisk_10': 0.3064296}, {'ndcg_5': 0.23059593, 'ndcg_10': 0.26243192, 'lndcg_5': 0.31740847, 'lndcg_10': 0.33891037, 'lndcg1_5': 0.31807494, 'lndcg1_10': 0.34030074, 'ndcg1_5': 0.23159264, 'ndcg1_10': 0.2622619, 'georisk_10': 0.30884507}, {'ndcg_5': 0.2331545, 'ndcg_10': 0.266195, 'lndcg_5': 0.31994182, 'lndcg_10': 0.34342673, 'lndcg1_5': 0.31937537, 'lndcg1_10': 0.34416687, 'ndcg1_5': 0.23585464, 'ndcg1_10': 0.26745787, 'georisk_10': 0.3131613}, {'ndcg_5': 0.23674376, 'ndcg_10': 0.26844922, 'lndcg_5': 0.32220182, 'lndcg_10': 0.34482467, 'lndcg1_5': 0.32417652, 'lndcg1_10': 0.34674424, 'ndcg1_5': 0.23832807, 'ndcg1_10': 0.26895717, 'georisk_10': 0.3134209}, {'ndcg_5': 0.24083996, 'ndcg_10': 0.2709167, 'lndcg_5': 0.32649955, 'lndcg_10': 0.34846476, 'lndcg1_5': 0.32764426, 'lndcg1_10': 0.349038, 'ndcg1_5': 0.2419591, 'ndcg1_10': 0.2711478, 'georisk_10': 0.31494123}, {'ndcg_5': 0.24388771, 'ndcg_10': 0.27223727, 'lndcg_5': 0.32907876, 'lndcg_10': 0.350453, 'lndcg1_5': 0.33195698, 'lndcg1_10': 0.351759, 'ndcg1_5': 0.24520653, 'ndcg1_10': 0.27414387, 'georisk_10': 0.31667283}, {'ndcg_5': 0.24808891, 'ndcg_10': 0.2762917, 'lndcg_5': 0.33477473, 'lndcg_10': 0.3543898, 'lndcg1_5': 0.33490956, 'lndcg1_10': 0.35466865, 'ndcg1_5': 0.24697015, 'ndcg1_10': 0.27619183, 'georisk_10': 0.31867787}, {'ndcg_5': 0.25077638, 'ndcg_10': 0.27771077, 'lndcg_5': 0.33589214, 'lndcg_10': 0.354192, 'lndcg1_5': 0.33808494, 'lndcg1_10': 0.35559925, 'ndcg1_5': 0.2518327, 'ndcg1_10': 0.27802274, 'georisk_10': 0.3181083}, {'ndcg_5': 0.25252566, 'ndcg_10': 0.27958384, 'lndcg_5': 0.33923927, 'lndcg_10': 0.3575291, 'lndcg1_5': 0.34121427, 'lndcg1_10': 0.35859233, 'ndcg1_5': 0.25396395, 'ndcg1_10': 0.28069052, 'georisk_10': 0.32033095}, {'ndcg_5': 0.2563357, 'ndcg_10': 0.2819818, 'lndcg_5': 0.34230417, 'lndcg_10': 0.35941797, 'lndcg1_5': 0.34221295, 'lndcg1_10': 0.3596407, 'ndcg1_5': 0.25695315, 'ndcg1_10': 0.2819295, 'georisk_10': 0.32134297}, {'ndcg_5': 0.25874963, 'ndcg_10': 0.28411597, 'lndcg_5': 0.3461182, 'lndcg_10': 0.36230025, 'lndcg1_5': 0.34623316, 'lndcg1_10': 0.3633437, 'ndcg1_5': 0.25849012, 'ndcg1_10': 0.284714, 'georisk_10': 0.3221826}, {'ndcg_5': 0.25920886, 'ndcg_10': 0.28556636, 'lndcg_5': 0.3476335, 'lndcg_10': 0.3634928, 'lndcg1_5': 0.34828004, 'lndcg1_10': 0.36447483, 'ndcg1_5': 0.26086706, 'ndcg1_10': 0.2862881, 'georisk_10': 0.32279813}, {'ndcg_5': 0.25964284, 'ndcg_10': 0.28524882, 'lndcg_5': 0.34983423, 'lndcg_10': 0.36449173, 'lndcg1_5': 0.34974754, 'lndcg1_10': 0.36480683, 'ndcg1_5': 0.26101187, 'ndcg1_10': 0.28581408, 'georisk_10': 0.32389227}, {'ndcg_5': 0.2652451, 'ndcg_10': 0.29164115, 'lndcg_5': 0.3512103, 'lndcg_10': 0.36842257, 'lndcg1_5': 0.35411575, 'lndcg1_10': 0.36931452, 'ndcg1_5': 0.265291, 'ndcg1_10': 0.29088208, 'georisk_10': 0.32715768}, {'ndcg_5': 0.26419762, 'ndcg_10': 0.2912598, 'lndcg_5': 0.3528341, 'lndcg_10': 0.36977902, 'lndcg1_5': 0.35334432, 'lndcg1_10': 0.37096226, 'ndcg1_5': 0.26600927, 'ndcg1_10': 0.29324907, 'georisk_10': 0.32716602}, {'ndcg_5': 0.26383883, 'ndcg_10': 0.28905103, 'lndcg_5': 0.35119882, 'lndcg_10': 0.36752343, 'lndcg1_5': 0.3534173, 'lndcg1_10': 0.36936346, 'ndcg1_5': 0.26417464, 'ndcg1_10': 0.29018205, 'georisk_10': 0.32646248}, {'ndcg_5': 0.26448146, 'ndcg_10': 0.2922399, 'lndcg_5': 0.3505296, 'lndcg_10': 0.3679294, 'lndcg1_5': 0.35281163, 'lndcg1_10': 0.3706935, 'ndcg1_5': 0.26338872, 'ndcg1_10': 0.29021555, 'georisk_10': 0.3273319}, {'ndcg_5': 0.26305148, 'ndcg_10': 0.29010144, 'lndcg_5': 0.3524926, 'lndcg_10': 0.3696712, 'lndcg1_5': 0.35302198, 'lndcg1_10': 0.369067, 'ndcg1_5': 0.26509255, 'ndcg1_10': 0.29070094, 'georisk_10': 0.32641274}, {'ndcg_5': 0.2670672, 'ndcg_10': 0.29334235, 'lndcg_5': 0.3526081, 'lndcg_10': 0.37105432, 'lndcg1_5': 0.3538829, 'lndcg1_10': 0.37217084, 'ndcg1_5': 0.26608032, 'ndcg1_10': 0.2928938, 'georisk_10': 0.32818016}, {'ndcg_5': 0.26662737, 'ndcg_10': 0.29291016, 'lndcg_5': 0.35432062, 'lndcg_10': 0.37154365, 'lndcg1_5': 0.35365683, 'lndcg1_10': 0.37205905, 'ndcg1_5': 0.26546127, 'ndcg1_10': 0.29344267, 'georisk_10': 0.32785034}, {'ndcg_5': 0.26680723, 'ndcg_10': 0.29295442, 'lndcg_5': 0.3542555, 'lndcg_10': 0.37152588, 'lndcg1_5': 0.35545167, 'lndcg1_10': 0.37286374, 'ndcg1_5': 0.2652238, 'ndcg1_10': 0.29304323, 'georisk_10': 0.32785305}, {'ndcg_5': 0.26604033, 'ndcg_10': 0.29321358, 'lndcg_5': 0.3549344, 'lndcg_10': 0.37159017, 'lndcg1_5': 0.35713387, 'lndcg1_10': 0.3732177, 'ndcg1_5': 0.26563692, 'ndcg1_10': 0.2930854, 'georisk_10': 0.32749215}, {'ndcg_5': 0.26491663, 'ndcg_10': 0.2921492, 'lndcg_5': 0.35540366, 'lndcg_10': 0.3720776, 'lndcg1_5': 0.3541483, 'lndcg1_10': 0.37199262, 'ndcg1_5': 0.26546675, 'ndcg1_10': 0.29287612, 'georisk_10': 0.32804057}, {'ndcg_5': 0.26543137, 'ndcg_10': 0.2928519, 'lndcg_5': 0.35558492, 'lndcg_10': 0.37211242, 'lndcg1_5': 0.3554993, 'lndcg1_10': 0.37359458, 'ndcg1_5': 0.26592427, 'ndcg1_10': 0.2931194, 'georisk_10': 0.32766768}, {'ndcg_5': 0.26718488, 'ndcg_10': 0.29366764, 'lndcg_5': 0.3561267, 'lndcg_10': 0.37369522, 'lndcg1_5': 0.3572047, 'lndcg1_10': 0.37323922, 'ndcg1_5': 0.265855, 'ndcg1_10': 0.2931332, 'georisk_10': 0.32802117}, {'ndcg_5': 0.26655778, 'ndcg_10': 0.29330197, 'lndcg_5': 0.3567061, 'lndcg_10': 0.37285268, 'lndcg1_5': 0.35640404, 'lndcg1_10': 0.37367642, 'ndcg1_5': 0.26719493, 'ndcg1_10': 0.29326686, 'georisk_10': 0.3275425}, {'ndcg_5': 0.26674348, 'ndcg_10': 0.2933678, 'lndcg_5': 0.35806814, 'lndcg_10': 0.37513548, 'lndcg1_5': 0.35746285, 'lndcg1_10': 0.37455302, 'ndcg1_5': 0.2667993, 'ndcg1_10': 0.29343843, 'georisk_10': 0.32929254}, {'ndcg_5': 0.26907533, 'ndcg_10': 0.2950585, 'lndcg_5': 0.35988498, 'lndcg_10': 0.3757687, 'lndcg1_5': 0.35874146, 'lndcg1_10': 0.3745854, 'ndcg1_5': 0.26937968, 'ndcg1_10': 0.29481632, 'georisk_10': 0.32956654}, {'ndcg_5': 0.26673543, 'ndcg_10': 0.29432818, 'lndcg_5': 0.3581581, 'lndcg_10': 0.37502506, 'lndcg1_5': 0.35882738, 'lndcg1_10': 0.37489992, 'ndcg1_5': 0.26892698, 'ndcg1_10': 0.29615426, 'georisk_10': 0.3280394}, {'ndcg_5': 0.2679405, 'ndcg_10': 0.29408658, 'lndcg_5': 0.35847515, 'lndcg_10': 0.3742413, 'lndcg1_5': 0.35765395, 'lndcg1_10': 0.3739544, 'ndcg1_5': 0.26822743, 'ndcg1_10': 0.2939461, 'georisk_10': 0.32881925}, {'ndcg_5': 0.26889446, 'ndcg_10': 0.2954097, 'lndcg_5': 0.3587824, 'lndcg_10': 0.3755604, 'lndcg1_5': 0.35943535, 'lndcg1_10': 0.3755306, 'ndcg1_5': 0.26926285, 'ndcg1_10': 0.2953264, 'georisk_10': 0.32863733}, {'ndcg_5': 0.2706069, 'ndcg_10': 0.2959633, 'lndcg_5': 0.35910055, 'lndcg_10': 0.37570375, 'lndcg1_5': 0.36141276, 'lndcg1_10': 0.3772856, 'ndcg1_5': 0.2703869, 'ndcg1_10': 0.2962458, 'georisk_10': 0.32850853}, {'ndcg_5': 0.26980686, 'ndcg_10': 0.29439706, 'lndcg_5': 0.36059186, 'lndcg_10': 0.37553668, 'lndcg1_5': 0.3615287, 'lndcg1_10': 0.37584934, 'ndcg1_5': 0.27004203, 'ndcg1_10': 0.29553884, 'georisk_10': 0.3294083}, {'ndcg_5': 0.26981968, 'ndcg_10': 0.29554808, 'lndcg_5': 0.36047328, 'lndcg_10': 0.37583452, 'lndcg1_5': 0.36107937, 'lndcg1_10': 0.3770035, 'ndcg1_5': 0.2697432, 'ndcg1_10': 0.29555067, 'georisk_10': 0.32886514}, {'ndcg_5': 0.26878765, 'ndcg_10': 0.2945067, 'lndcg_5': 0.36052352, 'lndcg_10': 0.37608576, 'lndcg1_5': 0.36087513, 'lndcg1_10': 0.375353, 'ndcg1_5': 0.2702371, 'ndcg1_10': 0.29603884, 'georisk_10': 0.33036852}, {'ndcg_5': 0.27259755, 'ndcg_10': 0.2970181, 'lndcg_5': 0.36366662, 'lndcg_10': 0.37759852, 'lndcg1_5': 0.3628194, 'lndcg1_10': 0.37715486, 'ndcg1_5': 0.27313465, 'ndcg1_10': 0.29796723, 'georisk_10': 0.33005384}]
2023-08-10 02:28:26,037 - allrank.utils.ltr_logging - INFO - Ending execution. Validation Metrics Evolution:
[{'ndcg_5': 0.1806599, 'ndcg_10': 0.20824847, 'lndcg_5': 0.26013035, 'lndcg_10': 0.28250617, 'lndcg1_5': 0.26196316, 'lndcg1_10': 0.2843247, 'ndcg1_5': 0.18248284, 'ndcg1_10': 0.21006158, 'georisk_10': 0.2761057}, {'ndcg_5': 0.18373187, 'ndcg_10': 0.21112971, 'lndcg_5': 0.26348516, 'lndcg_10': 0.28540877, 'lndcg1_5': 0.2652709, 'lndcg1_10': 0.28719443, 'ndcg1_5': 0.18551157, 'ndcg1_10': 0.21291104, 'georisk_10': 0.27700776}, {'ndcg_5': 0.18796673, 'ndcg_10': 0.2144773, 'lndcg_5': 0.26753208, 'lndcg_10': 0.28884935, 'lndcg1_5': 0.2693079, 'lndcg1_10': 0.29062814, 'ndcg1_5': 0.18975773, 'ndcg1_10': 0.21626703, 'georisk_10': 0.27933317}, {'ndcg_5': 0.1899929, 'ndcg_10': 0.21849595, 'lndcg_5': 0.27057695, 'lndcg_10': 0.29259953, 'lndcg1_5': 0.27231982, 'lndcg1_10': 0.29437634, 'ndcg1_5': 0.19175284, 'ndcg1_10': 0.22027628, 'georisk_10': 0.28183016}, {'ndcg_5': 0.19291162, 'ndcg_10': 0.22123411, 'lndcg_5': 0.27442396, 'lndcg_10': 0.29544, 'lndcg1_5': 0.27620968, 'lndcg1_10': 0.2972273, 'ndcg1_5': 0.19469734, 'ndcg1_10': 0.2230184, 'georisk_10': 0.2837432}, {'ndcg_5': 0.19957487, 'ndcg_10': 0.22624463, 'lndcg_5': 0.28067198, 'lndcg_10': 0.3004171, 'lndcg1_5': 0.28252366, 'lndcg1_10': 0.30220675, 'ndcg1_5': 0.20133512, 'ndcg1_10': 0.2280323, 'georisk_10': 0.28684372}, {'ndcg_5': 0.20266546, 'ndcg_10': 0.23059177, 'lndcg_5': 0.2835943, 'lndcg_10': 0.30501655, 'lndcg1_5': 0.28538, 'lndcg1_10': 0.30680227, 'ndcg1_5': 0.20445117, 'ndcg1_10': 0.23237869, 'georisk_10': 0.2890675}, {'ndcg_5': 0.2054158, 'ndcg_10': 0.23250997, 'lndcg_5': 0.28701904, 'lndcg_10': 0.30725282, 'lndcg1_5': 0.2887949, 'lndcg1_10': 0.30903038, 'ndcg1_5': 0.20720151, 'ndcg1_10': 0.23429686, 'georisk_10': 0.2901251}, {'ndcg_5': 0.20994289, 'ndcg_10': 0.23654608, 'lndcg_5': 0.2924984, 'lndcg_10': 0.31175905, 'lndcg1_5': 0.29428408, 'lndcg1_10': 0.31354353, 'ndcg1_5': 0.21172331, 'ndcg1_10': 0.2383289, 'georisk_10': 0.29304776}, {'ndcg_5': 0.2151017, 'ndcg_10': 0.24061854, 'lndcg_5': 0.29788783, 'lndcg_10': 0.31606147, 'lndcg1_5': 0.29967356, 'lndcg1_10': 0.3178472, 'ndcg1_5': 0.21688214, 'ndcg1_10': 0.24240023, 'georisk_10': 0.29570213}, {'ndcg_5': 0.2161944, 'ndcg_10': 0.2431496, 'lndcg_5': 0.2994014, 'lndcg_10': 0.3189204, 'lndcg1_5': 0.30114806, 'lndcg1_10': 0.32070252, 'ndcg1_5': 0.21798013, 'ndcg1_10': 0.24493457, 'georisk_10': 0.29732895}, {'ndcg_5': 0.21760201, 'ndcg_10': 0.24512278, 'lndcg_5': 0.30193692, 'lndcg_10': 0.32129166, 'lndcg1_5': 0.30372256, 'lndcg1_10': 0.32307735, 'ndcg1_5': 0.21939683, 'ndcg1_10': 0.24691527, 'georisk_10': 0.29822192}, {'ndcg_5': 0.22134459, 'ndcg_10': 0.24903215, 'lndcg_5': 0.30581927, 'lndcg_10': 0.32543182, 'lndcg1_5': 0.307644, 'lndcg1_10': 0.32721972, 'ndcg1_5': 0.22312503, 'ndcg1_10': 0.25081488, 'georisk_10': 0.30107316}, {'ndcg_5': 0.225902, 'ndcg_10': 0.25403026, 'lndcg_5': 0.31033614, 'lndcg_10': 0.3304977, 'lndcg1_5': 0.31205976, 'lndcg1_10': 0.33228624, 'ndcg1_5': 0.22769539, 'ndcg1_10': 0.2558126, 'georisk_10': 0.3042765}, {'ndcg_5': 0.22749057, 'ndcg_10': 0.25729132, 'lndcg_5': 0.31248018, 'lndcg_10': 0.3339979, 'lndcg1_5': 0.31432077, 'lndcg1_10': 0.3357971, 'ndcg1_5': 0.22931342, 'ndcg1_10': 0.25908214, 'georisk_10': 0.30678585}, {'ndcg_5': 0.23196214, 'ndcg_10': 0.26024035, 'lndcg_5': 0.31680354, 'lndcg_10': 0.3368927, 'lndcg1_5': 0.31862834, 'lndcg1_10': 0.33867913, 'ndcg1_5': 0.23374298, 'ndcg1_10': 0.2620019, 'georisk_10': 0.30895677}, {'ndcg_5': 0.2349937, 'ndcg_10': 0.26423565, 'lndcg_5': 0.31972733, 'lndcg_10': 0.34102446, 'lndcg1_5': 0.32152268, 'lndcg1_10': 0.34281686, 'ndcg1_5': 0.23685916, 'ndcg1_10': 0.26607957, 'georisk_10': 0.3107294}, {'ndcg_5': 0.23729791, 'ndcg_10': 0.26626337, 'lndcg_5': 0.3219684, 'lndcg_10': 0.3430508, 'lndcg1_5': 0.3237605, 'lndcg1_10': 0.34482214, 'ndcg1_5': 0.23907737, 'ndcg1_10': 0.26803365, 'georisk_10': 0.31167966}, {'ndcg_5': 0.24165562, 'ndcg_10': 0.2695743, 'lndcg_5': 0.32654783, 'lndcg_10': 0.3465344, 'lndcg1_5': 0.32833356, 'lndcg1_10': 0.34832013, 'ndcg1_5': 0.24344131, 'ndcg1_10': 0.27135965, 'georisk_10': 0.31437775}, {'ndcg_5': 0.24585241, 'ndcg_10': 0.27198485, 'lndcg_5': 0.3307396, 'lndcg_10': 0.349024, 'lndcg1_5': 0.33253425, 'lndcg1_10': 0.35081586, 'ndcg1_5': 0.24763598, 'ndcg1_10': 0.27376822, 'georisk_10': 0.31596598}, {'ndcg_5': 0.24772963, 'ndcg_10': 0.27465868, 'lndcg_5': 0.33338144, 'lndcg_10': 0.3520796, 'lndcg1_5': 0.33516017, 'lndcg1_10': 0.3538604, 'ndcg1_5': 0.24952136, 'ndcg1_10': 0.2764488, 'georisk_10': 0.31818345}, {'ndcg_5': 0.25101185, 'ndcg_10': 0.27480572, 'lndcg_5': 0.33649144, 'lndcg_10': 0.35160398, 'lndcg1_5': 0.33826718, 'lndcg1_10': 0.35338148, 'ndcg1_5': 0.25274622, 'ndcg1_10': 0.2765548, 'georisk_10': 0.3179736}, {'ndcg_5': 0.2508148, 'ndcg_10': 0.2773081, 'lndcg_5': 0.3366059, 'lndcg_10': 0.35394996, 'lndcg1_5': 0.3383805, 'lndcg1_10': 0.35572734, 'ndcg1_5': 0.2525945, 'ndcg1_10': 0.27908945, 'georisk_10': 0.3194097}, {'ndcg_5': 0.2544004, 'ndcg_10': 0.27932674, 'lndcg_5': 0.34031028, 'lndcg_10': 0.35630393, 'lndcg1_5': 0.34208485, 'lndcg1_10': 0.3580813, 'ndcg1_5': 0.25613478, 'ndcg1_10': 0.2810751, 'georisk_10': 0.32073197}, {'ndcg_5': 0.25746462, 'ndcg_10': 0.2831501, 'lndcg_5': 0.34413922, 'lndcg_10': 0.3609249, 'lndcg1_5': 0.34598967, 'lndcg1_10': 0.36275488, 'ndcg1_5': 0.2592321, 'ndcg1_10': 0.2849415, 'georisk_10': 0.3228941}, {'ndcg_5': 0.25701603, 'ndcg_10': 0.28313327, 'lndcg_5': 0.34318882, 'lndcg_10': 0.3607761, 'lndcg1_5': 0.34493867, 'lndcg1_10': 0.36253744, 'ndcg1_5': 0.25885916, 'ndcg1_10': 0.2849609, 'georisk_10': 0.32281825}, {'ndcg_5': 0.26029506, 'ndcg_10': 0.28500563, 'lndcg_5': 0.34702364, 'lndcg_10': 0.36293897, 'lndcg1_5': 0.3488606, 'lndcg1_10': 0.36476, 'ndcg1_5': 0.26207605, 'ndcg1_10': 0.28678766, 'georisk_10': 0.32398996}, {'ndcg_5': 0.26077545, 'ndcg_10': 0.28628746, 'lndcg_5': 0.34761274, 'lndcg_10': 0.36473972, 'lndcg1_5': 0.34928778, 'lndcg1_10': 0.36645165, 'ndcg1_5': 0.26256114, 'ndcg1_10': 0.28807318, 'georisk_10': 0.3248561}, {'ndcg_5': 0.2628079, 'ndcg_10': 0.2895939, 'lndcg_5': 0.3493628, 'lndcg_10': 0.36871573, 'lndcg1_5': 0.35115272, 'lndcg1_10': 0.37050292, 'ndcg1_5': 0.2646085, 'ndcg1_10': 0.29137072, 'georisk_10': 0.32698005}, {'ndcg_5': 0.26638186, 'ndcg_10': 0.29046234, 'lndcg_5': 0.35340163, 'lndcg_10': 0.3690887, 'lndcg1_5': 0.3551873, 'lndcg1_10': 0.370846, 'ndcg1_5': 0.26816756, 'ndcg1_10': 0.29226696, 'georisk_10': 0.3267353}, {'ndcg_5': 0.26634106, 'ndcg_10': 0.29055876, 'lndcg_5': 0.35350522, 'lndcg_10': 0.3698181, 'lndcg1_5': 0.35529682, 'lndcg1_10': 0.3715785, 'ndcg1_5': 0.2681268, 'ndcg1_10': 0.29234555, 'georisk_10': 0.3267139}, {'ndcg_5': 0.26628342, 'ndcg_10': 0.289793, 'lndcg_5': 0.35354248, 'lndcg_10': 0.3689333, 'lndcg1_5': 0.35534, 'lndcg1_10': 0.37072784, 'ndcg1_5': 0.26806912, 'ndcg1_10': 0.2915798, 'georisk_10': 0.32576177}, {'ndcg_5': 0.2643184, 'ndcg_10': 0.28984216, 'lndcg_5': 0.3516247, 'lndcg_10': 0.36972576, 'lndcg1_5': 0.3534434, 'lndcg1_10': 0.37151346, 'ndcg1_5': 0.2660836, 'ndcg1_10': 0.2916265, 'georisk_10': 0.32638785}, {'ndcg_5': 0.2660055, 'ndcg_10': 0.29140642, 'lndcg_5': 0.35302022, 'lndcg_10': 0.37112722, 'lndcg1_5': 0.35480592, 'lndcg1_10': 0.3729129, 'ndcg1_5': 0.26779124, 'ndcg1_10': 0.29319078, 'georisk_10': 0.3274514}, {'ndcg_5': 0.26570728, 'ndcg_10': 0.29033566, 'lndcg_5': 0.35360843, 'lndcg_10': 0.37037784, 'lndcg1_5': 0.35539415, 'lndcg1_10': 0.37216258, 'ndcg1_5': 0.26748338, 'ndcg1_10': 0.29211447, 'georisk_10': 0.32662556}, {'ndcg_5': 0.26579046, 'ndcg_10': 0.28995067, 'lndcg_5': 0.35407242, 'lndcg_10': 0.3703646, 'lndcg1_5': 0.35585812, 'lndcg1_10': 0.37215152, 'ndcg1_5': 0.26757622, 'ndcg1_10': 0.29173717, 'georisk_10': 0.32684213}, {'ndcg_5': 0.26663885, 'ndcg_10': 0.2910563, 'lndcg_5': 0.355437, 'lndcg_10': 0.3717384, 'lndcg1_5': 0.3572227, 'lndcg1_10': 0.37352413, 'ndcg1_5': 0.26840407, 'ndcg1_10': 0.29284143, 'georisk_10': 0.32714644}, {'ndcg_5': 0.26684946, 'ndcg_10': 0.29072195, 'lndcg_5': 0.35539255, 'lndcg_10': 0.37144172, 'lndcg1_5': 0.35717824, 'lndcg1_10': 0.37325588, 'ndcg1_5': 0.26863518, 'ndcg1_10': 0.2924887, 'georisk_10': 0.32689372}, {'ndcg_5': 0.26827005, 'ndcg_10': 0.29168347, 'lndcg_5': 0.35625947, 'lndcg_10': 0.37214905, 'lndcg1_5': 0.35804516, 'lndcg1_10': 0.37393478, 'ndcg1_5': 0.27005574, 'ndcg1_10': 0.29345027, 'georisk_10': 0.3276043}, {'ndcg_5': 0.26799372, 'ndcg_10': 0.2920657, 'lndcg_5': 0.35634196, 'lndcg_10': 0.37237003, 'lndcg1_5': 0.35812768, 'lndcg1_10': 0.37415576, 'ndcg1_5': 0.26979995, 'ndcg1_10': 0.29385224, 'georisk_10': 0.3270605}, {'ndcg_5': 0.2678552, 'ndcg_10': 0.29134703, 'lndcg_5': 0.3564895, 'lndcg_10': 0.37181178, 'lndcg1_5': 0.35827523, 'lndcg1_10': 0.3735691, 'ndcg1_5': 0.2696409, 'ndcg1_10': 0.2931327, 'georisk_10': 0.32689005}, {'ndcg_5': 0.26986408, 'ndcg_10': 0.29368037, 'lndcg_5': 0.35780618, 'lndcg_10': 0.3739367, 'lndcg1_5': 0.3595919, 'lndcg1_10': 0.37569404, 'ndcg1_5': 0.27164975, 'ndcg1_10': 0.29546547, 'georisk_10': 0.32825655}, {'ndcg_5': 0.26805195, 'ndcg_10': 0.2924269, 'lndcg_5': 0.35639498, 'lndcg_10': 0.37284142, 'lndcg1_5': 0.35814774, 'lndcg1_10': 0.3746266, 'ndcg1_5': 0.2698377, 'ndcg1_10': 0.2942135, 'georisk_10': 0.32792848}, {'ndcg_5': 0.26901156, 'ndcg_10': 0.29270038, 'lndcg_5': 0.3577018, 'lndcg_10': 0.37338123, 'lndcg1_5': 0.35945457, 'lndcg1_10': 0.37519342, 'ndcg1_5': 0.27079722, 'ndcg1_10': 0.29448608, 'georisk_10': 0.32780665}, {'ndcg_5': 0.27043322, 'ndcg_10': 0.29395282, 'lndcg_5': 0.3589551, 'lndcg_10': 0.37494332, 'lndcg1_5': 0.3607408, 'lndcg1_10': 0.37672788, 'ndcg1_5': 0.2722189, 'ndcg1_10': 0.29573855, 'georisk_10': 0.3280964}, {'ndcg_5': 0.27014303, 'ndcg_10': 0.29424253, 'lndcg_5': 0.35877338, 'lndcg_10': 0.37477347, 'lndcg1_5': 0.36059204, 'lndcg1_10': 0.37654227, 'ndcg1_5': 0.27190825, 'ndcg1_10': 0.29602683, 'georisk_10': 0.32886654}, {'ndcg_5': 0.2705697, 'ndcg_10': 0.29520974, 'lndcg_5': 0.35895652, 'lndcg_10': 0.37588048, 'lndcg1_5': 0.36074224, 'lndcg1_10': 0.3776676, 'ndcg1_5': 0.2723759, 'ndcg1_10': 0.29699683, 'georisk_10': 0.32911015}, {'ndcg_5': 0.27155715, 'ndcg_10': 0.29411253, 'lndcg_5': 0.36015284, 'lndcg_10': 0.37486303, 'lndcg1_5': 0.36197153, 'lndcg1_10': 0.3766495, 'ndcg1_5': 0.2733223, 'ndcg1_10': 0.29589763, 'georisk_10': 0.3286396}, {'ndcg_5': 0.27352583, 'ndcg_10': 0.2957135, 'lndcg_5': 0.3618188, 'lndcg_10': 0.37614167, 'lndcg1_5': 0.3636045, 'lndcg1_10': 0.37792736, 'ndcg1_5': 0.27531156, 'ndcg1_10': 0.29749918, 'georisk_10': 0.329209}, {'ndcg_5': 0.2731048, 'ndcg_10': 0.29523128, 'lndcg_5': 0.3617538, 'lndcg_10': 0.3759924, 'lndcg1_5': 0.36353952, 'lndcg1_10': 0.37777668, 'ndcg1_5': 0.27489048, 'ndcg1_10': 0.2970177, 'georisk_10': 0.3293114}]
2023-08-10 02:28:26,052 - allrank.utils.ltr_logging - INFO - Ending execution. Test Metrics Evolution:
[{'ndcg_5': 0.17714049886199634, 'ndcg_10': 0.20812090145245263, 'lndcg_5': 0.25620555306521425, 'lndcg_10': 0.2825790913928214, 'lndcg1_5': 0.2570881655983122, 'lndcg1_10': 0.2834617039259194, 'ndcg1_5': 0.1780231113950943, 'ndcg1_10': 0.2090035139855506}, {'ndcg_5': 0.1826611454941673, 'ndcg_10': 0.21282947447206982, 'lndcg_5': 0.2627101139874977, 'lndcg_10': 0.28768031394327526, 'lndcg1_5': 0.2635927265205957, 'lndcg1_10': 0.2885629264763732, 'ndcg1_5': 0.18354375802726527, 'ndcg1_10': 0.21371208700516778}, {'ndcg_5': 0.18652746593546005, 'ndcg_10': 0.21488993058160633, 'lndcg_5': 0.2656422976005876, 'lndcg_10': 0.28925992408488604, 'lndcg1_5': 0.26652491013368557, 'lndcg1_10': 0.290142536617984, 'ndcg1_5': 0.18741007846855803, 'ndcg1_10': 0.21577254311470428}, {'ndcg_5': 0.18755962727021638, 'ndcg_10': 0.21857252091713722, 'lndcg_5': 0.26734815709854076, 'lndcg_10': 0.2932783798920375, 'lndcg1_5': 0.2682307696316387, 'lndcg1_10': 0.29416099242513544, 'ndcg1_5': 0.18844223980331434, 'ndcg1_10': 0.21945513345023518}, {'ndcg_5': 0.19272795541043497, 'ndcg_10': 0.22103940892381282, 'lndcg_5': 0.27329107148466625, 'lndcg_10': 0.29573959608461026, 'lndcg1_5': 0.2741736840177642, 'lndcg1_10': 0.2966222086177082, 'ndcg1_5': 0.19361056794353296, 'ndcg1_10': 0.2219220214569108}, {'ndcg_5': 0.199384008898972, 'ndcg_10': 0.2260195110729505, 'lndcg_5': 0.2816909000209087, 'lndcg_10': 0.301536635819092, 'lndcg1_5': 0.2825735125540067, 'lndcg1_10': 0.30241924835219, 'ndcg1_5': 0.20026662143206997, 'ndcg1_10': 0.2269021236060485}, {'ndcg_5': 0.2015749479194702, 'ndcg_10': 0.2290718980069217, 'lndcg_5': 0.28466724354165035, 'lndcg_10': 0.304721405802911, 'lndcg1_5': 0.2855498560747483, 'lndcg1_10': 0.305604018336009, 'ndcg1_5': 0.20245756045256816, 'ndcg1_10': 0.22995451054001967}, {'ndcg_5': 0.20563410050110104, 'ndcg_10': 0.23236562362134255, 'lndcg_5': 0.2893632187172716, 'lndcg_10': 0.3088955685616815, 'lndcg1_5': 0.2902458312503696, 'lndcg1_10': 0.30977818109477945, 'ndcg1_5': 0.206516713034199, 'ndcg1_10': 0.2332482361544405}, {'ndcg_5': 0.2085601773369951, 'ndcg_10': 0.2362599425316069, 'lndcg_5': 0.293113075864466, 'lndcg_10': 0.3132006676456415, 'lndcg1_5': 0.29399568839756396, 'lndcg1_10': 0.3140832801787395, 'ndcg1_5': 0.20944278987009307, 'ndcg1_10': 0.23714255506470486}, {'ndcg_5': 0.21156400307303533, 'ndcg_10': 0.2396902538568455, 'lndcg_5': 0.2971710977102414, 'lndcg_10': 0.317530875425752, 'lndcg1_5': 0.2980537102433394, 'lndcg1_10': 0.31841348795884994, 'ndcg1_5': 0.2124466156061333, 'ndcg1_10': 0.2405728663899435}, {'ndcg_5': 0.21585879131059385, 'ndcg_10': 0.24408638353029644, 'lndcg_5': 0.30234058224086563, 'lndcg_10': 0.3222912642833148, 'lndcg1_5': 0.3032231947739636, 'lndcg1_10': 0.32317387681641274, 'ndcg1_5': 0.2167414038436918, 'ndcg1_10': 0.2449689960633944}, {'ndcg_5': 0.2175748670222056, 'ndcg_10': 0.24816869497042368, 'lndcg_5': 0.3041314102941353, 'lndcg_10': 0.32663466618981685, 'lndcg1_5': 0.3050140228272333, 'lndcg1_10': 0.3275172787229148, 'ndcg1_5': 0.21845747955530356, 'ndcg1_10': 0.24905130750352164}, {'ndcg_5': 0.22065290082020245, 'ndcg_10': 0.2511578365353106, 'lndcg_5': 0.3079716866831746, 'lndcg_10': 0.33071376650501766, 'lndcg1_5': 0.30885429921627255, 'lndcg1_10': 0.3315963790381156, 'ndcg1_5': 0.2215355133533004, 'ndcg1_10': 0.2520404490684086}, {'ndcg_5': 0.22433836420220418, 'ndcg_10': 0.2563593211947692, 'lndcg_5': 0.3130695955711299, 'lndcg_10': 0.3364569123849945, 'lndcg1_5': 0.31395220810422786, 'lndcg1_10': 0.33733952491809244, 'ndcg1_5': 0.22522097673530214, 'ndcg1_10': 0.25724193372786713}, {'ndcg_5': 0.22878989472914882, 'ndcg_10': 0.26090931163656356, 'lndcg_5': 0.31825904137160616, 'lndcg_10': 0.3412235037054375, 'lndcg1_5': 0.31914165390470417, 'lndcg1_10': 0.3421061162385355, 'ndcg1_5': 0.22967250726224678, 'ndcg1_10': 0.2617919241696615}, {'ndcg_5': 0.23222104937099766, 'ndcg_10': 0.265165342950346, 'lndcg_5': 0.32179065479776825, 'lndcg_10': 0.34582133328588877, 'lndcg1_5': 0.32267326733086626, 'lndcg1_10': 0.3467039458189867, 'ndcg1_5': 0.23310366190409565, 'ndcg1_10': 0.26604795548344395}, {'ndcg_5': 0.23444061872771832, 'ndcg_10': 0.26677860592928837, 'lndcg_5': 0.3238841116640584, 'lndcg_10': 0.34712758074301486, 'lndcg1_5': 0.32476672419715635, 'lndcg1_10': 0.3480101932761128, 'ndcg1_5': 0.23532323126081628, 'ndcg1_10': 0.26766121846238633}, {'ndcg_5': 0.23813777135303865, 'ndcg_10': 0.2683269326146388, 'lndcg_5': 0.3277332441341567, 'lndcg_10': 0.3488559494680154, 'lndcg1_5': 0.3286158566672547, 'lndcg1_10': 0.34973856200111336, 'ndcg1_5': 0.23902038388613664, 'ndcg1_10': 0.26920954514773676}, {'ndcg_5': 0.24225969274481923, 'ndcg_10': 0.27001213541927216, 'lndcg_5': 0.3328506965432052, 'lndcg_10': 0.3508686802842462, 'lndcg1_5': 0.3337333090763032, 'lndcg1_10': 0.3517512928173442, 'ndcg1_5': 0.2431423052779172, 'ndcg1_10': 0.2708947479523701}, {'ndcg_5': 0.24423487789876955, 'ndcg_10': 0.27247212478861027, 'lndcg_5': 0.33480405623571224, 'lndcg_10': 0.353293704368365, 'lndcg1_5': 0.33568666876881026, 'lndcg1_10': 0.354176316901463, 'ndcg1_5': 0.24511749043186754, 'ndcg1_10': 0.27335473732170823}, {'ndcg_5': 0.24628910370192425, 'ndcg_10': 0.2754896491034096, 'lndcg_5': 0.3371486258537967, 'lndcg_10': 0.3569175730175104, 'lndcg1_5': 0.33803123838689464, 'lndcg1_10': 0.3578001855506084, 'ndcg1_5': 0.2471717162350222, 'ndcg1_10': 0.2763722616365076}, {'ndcg_5': 0.25010448907248517, 'ndcg_10': 0.2755910924262737, 'lndcg_5': 0.3411065569088651, 'lndcg_10': 0.35682154977337405, 'lndcg1_5': 0.34198916944196306, 'lndcg1_10': 0.357704162306472, 'ndcg1_5': 0.25098710160558313, 'ndcg1_10': 0.2764737049593717}, {'ndcg_5': 0.2530484013013766, 'ndcg_10': 0.2765636113072961, 'lndcg_5': 0.3441510610136821, 'lndcg_10': 0.35744360561309546, 'lndcg1_5': 0.34503367354678005, 'lndcg1_10': 0.3583262181461934, 'ndcg1_5': 0.25393101383447464, 'ndcg1_10': 0.2774462238403941}, {'ndcg_5': 0.25596343755427, 'ndcg_10': 0.2792408103745672, 'lndcg_5': 0.34790362466986835, 'lndcg_10': 0.3609075847641556, 'lndcg1_5': 0.3487862372029663, 'lndcg1_10': 0.36179019729725354, 'ndcg1_5': 0.25684605008736794, 'ndcg1_10': 0.2801234229076652}, {'ndcg_5': 0.2579295314518257, 'ndcg_10': 0.28128394632371345, 'lndcg_5': 0.35034996516255756, 'lndcg_10': 0.36399875605075116, 'lndcg1_5': 0.3512325776956555, 'lndcg1_10': 0.3648813685838491, 'ndcg1_5': 0.2588121439849237, 'ndcg1_10': 0.2821665588568114}, {'ndcg_5': 0.2586797328738992, 'ndcg_10': 0.2828913563031026, 'lndcg_5': 0.3516071497566642, 'lndcg_10': 0.3655082984265814, 'lndcg1_5': 0.35248976228976214, 'lndcg1_10': 0.36639091095967935, 'ndcg1_5': 0.2595623454069972, 'ndcg1_10': 0.28377396883620054}, {'ndcg_5': 0.26278733555814043, 'ndcg_10': 0.28850483430376633, 'lndcg_5': 0.3554835945972594, 'lndcg_10': 0.3711795611350662, 'lndcg1_5': 0.3563662071303574, 'lndcg1_10': 0.3720621736681642, 'ndcg1_5': 0.2636699480912384, 'ndcg1_10': 0.2893874468368643}, {'ndcg_5': 0.26614423484226113, 'ndcg_10': 0.29191523843370565, 'lndcg_5': 0.3594996225963391, 'lndcg_10': 0.37486792331743246, 'lndcg1_5': 0.36038223512943707, 'lndcg1_10': 0.3757505358505305, 'ndcg1_5': 0.2670268473753591, 'ndcg1_10': 0.2927978509668036}, {'ndcg_5': 0.2641337726621282, 'ndcg_10': 0.2896579221433788, 'lndcg_5': 0.35677671712841874, 'lndcg_10': 0.3725504739394975, 'lndcg1_5': 0.3576593296615167, 'lndcg1_10': 0.37343308647259543, 'ndcg1_5': 0.26501638519522613, 'ndcg1_10': 0.2905405346764768}, {'ndcg_5': 0.26355682930994995, 'ndcg_10': 0.289953684900699, 'lndcg_5': 0.35601500069255165, 'lndcg_10': 0.3731939956738322, 'lndcg1_5': 0.3568976132256496, 'lndcg1_10': 0.3740766082069302, 'ndcg1_5': 0.2644394418430479, 'ndcg1_10': 0.29083629743379696}, {'ndcg_5': 0.2646835103763993, 'ndcg_10': 0.2915122474034875, 'lndcg_5': 0.3573340835864179, 'lndcg_10': 0.37485585916260566, 'lndcg1_5': 0.3582166961195159, 'lndcg1_10': 0.3757384716957036, 'ndcg1_5': 0.26556612290949727, 'ndcg1_10': 0.29239485993658554}, {'ndcg_5': 0.2665245094793701, 'ndcg_10': 0.29243468518388366, 'lndcg_5': 0.3601803804446172, 'lndcg_10': 0.3760724863531891, 'lndcg1_5': 0.36106299297771516, 'lndcg1_10': 0.3769550988862871, 'ndcg1_5': 0.26740712201246813, 'ndcg1_10': 0.2933172977169816}, {'ndcg_5': 0.26697508933916925, 'ndcg_10': 0.2917509435007642, 'lndcg_5': 0.36120534287200645, 'lndcg_10': 0.3762119313198265, 'lndcg1_5': 0.36208795540510447, 'lndcg1_10': 0.37709454385292446, 'ndcg1_5': 0.2678577018722672, 'ndcg1_10': 0.2926335560338622}, {'ndcg_5': 0.2685825611488032, 'ndcg_10': 0.2938966561881321, 'lndcg_5': 0.3621198908633738, 'lndcg_10': 0.37806126994321154, 'lndcg1_5': 0.3630025033964718, 'lndcg1_10': 0.3789438824763095, 'ndcg1_5': 0.2694651736819012, 'ndcg1_10': 0.29477926872123006}, {'ndcg_5': 0.2674465953772649, 'ndcg_10': 0.2926210007246431, 'lndcg_5': 0.36229790749133894, 'lndcg_10': 0.3780711714115579, 'lndcg1_5': 0.36318052002443696, 'lndcg1_10': 0.3789537839446559, 'ndcg1_5': 0.2683292079103629, 'ndcg1_10': 0.29350361325774105}, {'ndcg_5': 0.2687856449342576, 'ndcg_10': 0.2936526083217704, 'lndcg_5': 0.363923314913196, 'lndcg_10': 0.3792047517099634, 'lndcg1_5': 0.364805927446294, 'lndcg1_10': 0.3800873642430614, 'ndcg1_5': 0.26966825746735557, 'ndcg1_10': 0.2945352208548684}, {'ndcg_5': 0.26747333568635734, 'ndcg_10': 0.2929813197706931, 'lndcg_5': 0.36256260744212826, 'lndcg_10': 0.3787369344371235, 'lndcg1_5': 0.3634452199752262, 'lndcg1_10': 0.37961954697022143, 'ndcg1_5': 0.26835594821945535, 'ndcg1_10': 0.29386393230379104}, {'ndcg_5': 0.2692151545553963, 'ndcg_10': 0.29403060802615233, 'lndcg_5': 0.364261967781882, 'lndcg_10': 0.37933233604723604, 'lndcg1_5': 0.36514458031498, 'lndcg1_10': 0.380214948580334, 'ndcg1_5': 0.2700977670884943, 'ndcg1_10': 0.2949132205592503}]
2023-08-10 02:28:26,160 - allrank.utils.ltr_logging - INFO - created paths container PathsContainer(local_base_output_path='results-new/', base_output_path='results-new/', output_dir='results-new/results\\analiseyahoo', tensorboard_output_path='results-new/tb_evals\\single\\analiseyahoo', config_path='localtemp_config.json')
2023-08-10 02:28:26,161 - allrank.utils.ltr_logging - INFO - Config:
 {'click_model': None,
 'data': DataConfig(path='D:\\Colecoes\\BD\\yahoo-c14\\l2r', num_workers=0, batch_size=20, slate_length=100, validation_ds_role='vali'),
 'detect_anomaly': True,
 'expected_metrics': {'val': {'georisk_10': 0.0,
                              'lndcg_10': 0.0,
                              'lndcg_5': 0.0,
                              'ndcg_10': 0.0,
                              'ndcg_5': 0.0}},
 'loss': NameArgsConfig(name='geoRiskSpearmanLoss', args={}),
 'lr_scheduler': NameArgsConfig(name=None, args={'step_size': 800, 'gamma': 0.5}),
 'metrics': defaultdict(<class 'list'>,
                        {'georisk': [10],
                         'lndcg': [5,
                                   10],
                         'lndcg1': [5,
                                    10],
                         'ndcg': [5,
                                  10],
                         'ndcg1': [5,
                                   10]}),
 'model': ModelConfig(fc_model={}, transformer=TransformerConfig(N=2, d_ff=32, h=2, positional_encoding=None, dropout=0.3), post_model={'output_activation': 'Sigmoid', 'd_output': 1}),
 'optimizer': NameArgsConfig(name='Adam', args={'lr': 0.0001}),
 'training': TrainingConfig(epochs=25, gradient_clipping_norm=None, early_stopping_patience=100),
 'val_metric': 'ndcg_10'}
2023-08-10 02:28:26,162 - allrank.utils.ltr_logging - INFO - will execute copy "localtemp_config.json" "results-new/results\analiseyahoo\used_config.json"
2023-08-10 02:28:26,189 - allrank.utils.ltr_logging - INFO - exit_code = 0
2023-08-10 02:28:26,189 - allrank.utils.ltr_logging - INFO - will load train data from D:\Colecoes\BD\yahoo-c14\l2r\Norm.train.txt
2023-08-10 02:28:30,880 - allrank.utils.ltr_logging - INFO - loaded dataset from <_io.BufferedReader name='D:\\Colecoes\\BD\\yahoo-c14\\l2r\\Norm.train.txt'> and got x shape (34815, 700), y shape (34815,) and query_ids shape (34815,)
2023-08-10 02:28:30,937 - allrank.utils.ltr_logging - INFO - loaded dataset with 1266 queries
2023-08-10 02:28:30,937 - allrank.utils.ltr_logging - INFO - longest query had 117 documents
2023-08-10 02:28:30,944 - allrank.utils.ltr_logging - INFO - train DS shape: [1266, 117, 700]
2023-08-10 02:28:30,944 - allrank.utils.ltr_logging - INFO - will load vali data from D:\Colecoes\BD\yahoo-c14\l2r\Norm.vali.txt
2023-08-10 02:28:35,652 - allrank.utils.ltr_logging - INFO - loaded dataset from <_io.BufferedReader name='D:\\Colecoes\\BD\\yahoo-c14\\l2r\\Norm.vali.txt'> and got x shape (34881, 700), y shape (34881,) and query_ids shape (34881,)
2023-08-10 02:28:35,708 - allrank.utils.ltr_logging - INFO - loaded dataset with 1266 queries
2023-08-10 02:28:35,708 - allrank.utils.ltr_logging - INFO - longest query had 118 documents
2023-08-10 02:28:35,715 - allrank.utils.ltr_logging - INFO - vali DS shape: [1266, 118, 700]
2023-08-10 02:28:35,716 - allrank.utils.ltr_logging - INFO - Will pad to the longest slate: 118
2023-08-10 02:28:35,716 - allrank.utils.ltr_logging - INFO - will load test data from D:\Colecoes\BD\yahoo-c14\l2r\Norm.test.txt
2023-08-10 02:28:40,353 - allrank.utils.ltr_logging - INFO - loaded dataset from <_io.BufferedReader name='D:\\Colecoes\\BD\\yahoo-c14\\l2r\\Norm.test.txt'> and got x shape (34881, 700), y shape (34881,) and query_ids shape (34881,)
2023-08-10 02:28:40,416 - allrank.utils.ltr_logging - INFO - loaded dataset with 1266 queries
2023-08-10 02:28:40,416 - allrank.utils.ltr_logging - INFO - longest query had 118 documents
2023-08-10 02:28:40,424 - allrank.utils.ltr_logging - INFO - test DS shape: [1266, 118, 700]
2023-08-10 02:28:40,424 - allrank.utils.ltr_logging - INFO - Will pad to the longest slate: 118
2023-08-10 02:28:40,426 - allrank.utils.ltr_logging - INFO - total batch size is 20
2023-08-10 02:28:40,427 - allrank.utils.ltr_logging - INFO - Model training will execute on cpu
2023-08-10 02:28:40,466 - allrank.utils.ltr_logging - INFO - Model has 4024365 trainable parameters
2023-08-10 02:28:40,467 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 02:43:21,056 - allrank.utils.ltr_logging - INFO - Epoch : 0 Train loss: 0.2747219307774804 Val loss: 0.23275271091039335 Train ndcg_5 0.41963163018226624 Train ndcg_10 0.5000848770141602 Train lndcg_5 0.5343219041824341 Train lndcg_10 0.6027869582176208 Train lndcg1_5 0.550774872303009 Train lndcg1_10 0.6200681924819946 Train ndcg1_5 0.43551579117774963 Train ndcg1_10 0.5151742100715637 Train georisk_10 0.4488844871520996 Val ndcg_5 0.40791386365890503 Val ndcg_10 0.49079662561416626 Val lndcg_5 0.5284556746482849 Val lndcg_10 0.6011630892753601 Val lndcg1_5 0.5466229915618896 Val lndcg1_10 0.6193305253982544 Val ndcg1_5 0.42608126997947693 Val ndcg1_10 0.5089641213417053 Val georisk_10 0.44015973806381226
2023-08-10 02:43:21,057 - allrank.utils.ltr_logging - INFO - Current:0.49079662561416626 Best:0.0
2023-08-10 02:43:39,168 - allrank.utils.ltr_logging - INFO - MY-flag writted predictions - because model is best on validation. Test metrics: {'ndcg_5': 0.4079063522475752, 'ndcg_10': 0.4907767410632243, 'lndcg_5': 0.5284446777850241, 'lndcg_10': 0.6011378412779609, 'lndcg1_5': 0.5466121343411063, 'lndcg1_10': 0.619305297834043, 'ndcg1_5': 0.42607380880365736, 'ndcg1_10': 0.5089441976193064} 
2023-08-10 02:43:39,168 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
2023-08-10 02:58:19,196 - allrank.utils.ltr_logging - INFO - Epoch : 1 Train loss: 0.22078264343418405 Val loss: 0.23075140704287547 Train ndcg_5 0.4081052541732788 Train ndcg_10 0.48666343092918396 Train lndcg_5 0.5277834534645081 Train lndcg_10 0.600131094455719 Train lndcg1_5 0.5479238629341125 Train lndcg1_10 0.6212714314460754 Train ndcg1_5 0.4341423511505127 Train ndcg1_10 0.5130478143692017 Train georisk_10 0.4445136785507202 Val ndcg_5 0.4011159837245941 Val ndcg_10 0.4816814363002777 Val lndcg_5 0.5234181880950928 Val lndcg_10 0.5943129062652588 Val lndcg1_5 0.5415857434272766 Val lndcg1_10 0.6124804019927979 Val ndcg1_5 0.41928327083587646 Val ndcg1_10 0.4998490512371063 Val georisk_10 0.4358260929584503
2023-08-10 02:58:19,198 - allrank.utils.ltr_logging - INFO - Current:0.4816814363002777 Best:0.49079662561416626
2023-08-10 02:58:37,815 - allrank.utils.ltr_logging - INFO - Current learning rate: 0.0001
